{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12.  Measure Summaries of Summaries Accuracy for Submissions and Comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries, load submissions and comments with summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9188/2787036845.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nan_rows_df = nan_rows_df.append(extract_nan_rows(df, \"tfcc_top_20_summaries_of_summaries\"))\n",
      "/tmp/ipykernel_9188/2787036845.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nan_rows_df = nan_rows_df.append(extract_nan_rows(comments_df, \"tfcc_comments_summaries_of_summaries\"))\n",
      "/tmp/ipykernel_9188/2787036845.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nan_rows_df = nan_rows_df.append(extract_nan_rows(pegasus_df, \"tfcc_top_20_summaries_of_summaries_pegasus\"))\n",
      "/tmp/ipykernel_9188/2787036845.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nan_rows_df = nan_rows_df.append(extract_nan_rows(pegasus_comments_df, \"tfcc_comments_summaries_of_summaries_pegasus\"))\n",
      "/tmp/ipykernel_9188/2787036845.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nan_rows_df = nan_rows_df.append(extract_nan_rows(cohere_df, \"tfcc_top_20_summaries_of_summaries\"))\n",
      "/tmp/ipykernel_9188/2787036845.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nan_rows_df = nan_rows_df.append(extract_nan_rows(cohere_comments_df, \"tfcc_comments_summaries_of_summaries_cohere\"))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_nan_rows(df, name):\n",
    "    nan_rows = df[df['new_summary'].isna()]\n",
    "    nan_rows['source'] = name\n",
    "    return nan_rows\n",
    "\n",
    "# Load DataFrames\n",
    "df = pd.read_csv('tfcc_top_20_summaries_of_summaries.csv')\n",
    "comments_df = pd.read_csv('tfcc_comments_summaries_of_summaries.csv')\n",
    "pegasus_df = pd.read_csv('tfcc_top_20_summaries_of_summaries_pegasus.csv')\n",
    "pegasus_comments_df = pd.read_csv('tfcc_comments_summaries_of_summaries_pegasus.csv')\n",
    "cohere_df = pd.read_csv('tfcc_top_20_summaries_of_summaries.csv')\n",
    "cohere_comments_df = pd.read_csv('tfcc_comments_summaries_of_summaries_cohere.csv')\n",
    "\n",
    "# Extract rows with NaN values in the 'summary' column\n",
    "nan_rows_df = pd.DataFrame()\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(df, \"tfcc_top_20_summaries_of_summaries\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(comments_df, \"tfcc_comments_summaries_of_summaries\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(pegasus_df, \"tfcc_top_20_summaries_of_summaries_pegasus\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(pegasus_comments_df, \"tfcc_comments_summaries_of_summaries_pegasus\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(cohere_df, \"tfcc_top_20_summaries_of_summaries\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(cohere_comments_df, \"tfcc_comments_summaries_of_summaries_cohere\"))\n",
    "\n",
    "# Remove rows with NaN values from the original DataFrames\n",
    "df = df.dropna(subset=['new_summary'])\n",
    "comments_df = comments_df.dropna(subset=['new_summary'])\n",
    "pegasus_df = pegasus_df.dropna(subset=['new_summary'])\n",
    "pegasus_comments_df = pegasus_comments_df.dropna(subset=['new_summary'])\n",
    "cohere_df = cohere_df.dropna(subset=['new_summary'])\n",
    "cohere_comments_df = cohere_comments_df.dropna(subset=['new_summary'])\n",
    "\n",
    "# Print the DataFrame containing rows with NaN values in the 'summary' column\n",
    "nan_rows_df.to_csv('summary_errors.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>new_summary</th>\n",
       "      <th>theme</th>\n",
       "      <th>Count</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>source</th>\n",
       "      <th>concatenated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [topic, summary, title, new_summary, theme, Count, topic_name, source, concatenated_summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure summary accuracy and drop all rows that are below 0.8 F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows using the shape attribute\n",
    "start_num_rows = df.shape[0]\n",
    "pegasus_start_num_rows = pegasus_df.shape[0]\n",
    "cohere_start_num_rows = cohere_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI - Measuring accuracy on 98 rows.\n",
      "Pegasus - Measuring accuracy on 205 rows.\n",
      "COhere - Measuring accuracy on 98 rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"OpenAI - Measuring accuracy on \" +str(start_num_rows) + \" rows.\")\n",
    "print(\"Pegasus - Measuring accuracy on \" +str(pegasus_start_num_rows) + \" rows.\")\n",
    "print(\"COhere - Measuring accuracy on \" +str(cohere_start_num_rows) + \" rows.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy for OpenAI submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02829396d4a74ba7b831a41466cc79ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844b5bb54f984f8d9b918ce19a5a317c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7.30 seconds, 13.43 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your existing code\n",
    "selftext = df['summary']\n",
    "summary = df['new_summary']\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy for Pegasus submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef99a43bd3334a5eb847e2e2d9336923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ec62f7b02b4f00b9e0cc502a904b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 13.67 seconds, 14.99 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "selftext = pegasus_df['summary']\n",
    "summary = pegasus_df['new_summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "pegasus_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy for Cohere submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22aac17b15e43b8ac96b7075e75d0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07449845d9049cc8b7ed53ed1d4680b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7.42 seconds, 13.21 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "selftext = cohere_df['summary']\n",
    "summary = cohere_df['new_summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "cohere_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display average accuracy score for OpenAI, Pegasus, and Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataframe</th>\n",
       "      <th>Average F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>df</td>\n",
       "      <td>0.847731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pegasus_df</td>\n",
       "      <td>0.895354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cohere_df</td>\n",
       "      <td>0.847731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Assuming you have already loaded the dataframes: df, pegasus_df, and cohere_df\n",
    "\n",
    "# Calculate the average F1 scores\n",
    "df_avg_f1 = df['bert_f1'].mean()\n",
    "pegasus_avg_f1 = pegasus_df['bert_f1'].mean()\n",
    "cohere_avg_f1 = cohere_df['bert_f1'].mean()\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "data = {\n",
    "    'Dataframe': ['df', 'pegasus_df', 'cohere_df'],\n",
    "    'Average F1': [df_avg_f1, pegasus_avg_f1, cohere_avg_f1]\n",
    "}\n",
    "\n",
    "# Create a new dataframe to display the results\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the results in a simple table\n",
    "display(HTML(results_df.to_html(index=False)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results for OpenAI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 rows were >= 0.8 F1 and 0 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "df2 = df[df['bert_f1'] < 0.8] \n",
    "df = df[df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = df.shape[0]\n",
    "\n",
    "removed_num = df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tfcc_submissions_summaries_of_summaries_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results for Pegasus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 rows were >= 0.8 F1 and 0 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "pegasus_df2 = pegasus_df[pegasus_df['bert_f1'] < 0.8] \n",
    "pegasus_df = pegasus_df[pegasus_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = pegasus_df.shape[0]\n",
    "\n",
    "removed_num = pegasus_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasus_df.to_csv('tfcc_submissions_summaries_of_summaries_pegasus_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results for Cohere test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 rows were >= 0.8 F1 and 0 were below 0.8 F1.\n"
     ]
    }
   ],
   "source": [
    "temp_df2 = cohere_df[cohere_df['bert_f1'] < 0.8] \n",
    "temp_df = cohere_df[cohere_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = temp_df.shape[0]\n",
    "\n",
    "removed_num = temp_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_df.to_csv('tfcc_submissions_summaries_of_summaries_cohere_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat accuracy measurement process for comments.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Measuring accuracy on 32 rows.\n",
      "Pegasus Measuring accuracy on 20 rows.\n",
      "Cohere Measuring accuracy on 20 rows.\n"
     ]
    }
   ],
   "source": [
    "# get the number of rows using the shape attribute\n",
    "start_num_rows = comments_df.shape[0]\n",
    "print(\"OpenAI Measuring accuracy on \" +str(start_num_rows) + \" rows.\")\n",
    "\n",
    "pegasus_start_num_rows = pegasus_comments_df.shape[0]\n",
    "print(\"Pegasus Measuring accuracy on \" +str(pegasus_start_num_rows) + \" rows.\")\n",
    "\n",
    "cohere_start_num_rows = cohere_comments_df.shape[0]\n",
    "print(\"Cohere Measuring accuracy on \" +str(cohere_start_num_rows) + \" rows.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure OpenAI comments summaries accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0a39a3d0de45539e6b93f58c0538df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0235feb78e5f409fa67cf7c7c4bc8481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.98 seconds, 10.74 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Select the columns to compare\n",
    "selftext = comments_df['summary']\n",
    "summary = comments_df['new_summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "comments_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure Pegasus comments summaries accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dd21fe7b7e4abcbdf052f467cee4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb97b3d57e34ab4b7f3e6ca4e732211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.52 seconds, 13.12 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Select the columns to compare\n",
    "selftext = pegasus_comments_df['summary']\n",
    "summary = pegasus_comments_df['new_summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "pegasus_comments_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure Cohere comments summaries accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>concatenated_summary</th>\n",
       "      <th>new_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>I work in a call center. I got a call from a v...</td>\n",
       "      <td>I work in a call center. I got a call from a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I used to work for the mental health branch of...</td>\n",
       "      <td>I had a mother call me one time to request we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I had to go back and reread that. You're givin...</td>\n",
       "      <td>OP is a salesperson who sold a TV to a custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>I work for a different variety of insurance an...</td>\n",
       "      <td>I'm sorry but I'm not going to give you a clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A woman called a dental office to ask for her ...</td>\n",
       "      <td>I work in a call center. I deal with a lot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A woman in the US has been filmed berating a c...</td>\n",
       "      <td>A woman in the US has been filmed berating a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>I had a similar situation when doing customer ...</td>\n",
       "      <td>I'm an ex-call center worker. I worked for a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>I quit my job after 20 years and made over 27 ...</td>\n",
       "      <td>I worked at a call center. We would drink on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>I don't blame you for being upset. I would be ...</td>\n",
       "      <td>I'm so sorry you had to go through that. Ive h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>I was in retail for a decade. I was in a call ...</td>\n",
       "      <td>I've been in a call centre for 5 years. I cry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>I work in a call center and we have a lot of c...</td>\n",
       "      <td>I work in a call center and we have a lot of c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>I enjoy calls like this. Wait sir what color a...</td>\n",
       "      <td>I used to work for a credit card processor. We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>I have worked in the contact center industry f...</td>\n",
       "      <td>I have worked in the contact center industry f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>I'm a cable company customer service rep. I've...</td>\n",
       "      <td>I'm a cable company customer service rep. I've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>I worked in a call centre, one night a woman c...</td>\n",
       "      <td>I worked in a call centre, one night a woman c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>I worked at a call center for a major credit c...</td>\n",
       "      <td>I'm a call center worker. I get some really di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>I'm sure you're aware of the recent changes to...</td>\n",
       "      <td>I'm sure you're aware of the recent changes to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>I once had an elderly couple calling about the...</td>\n",
       "      <td>I once had an elderly couple calling about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>I'm pretty sure I know where you work and I'm ...</td>\n",
       "      <td>The customer is always right. Even when they'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>I get a request for a CEO once a week. The cus...</td>\n",
       "      <td>I get a request for a CEO once a week. The cus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                               concatenated_summary  \\\n",
       "0     0.0  I work in a call center. I got a call from a v...   \n",
       "1     1.0  I used to work for the mental health branch of...   \n",
       "2     2.0  I had to go back and reread that. You're givin...   \n",
       "3     3.0  I work for a different variety of insurance an...   \n",
       "4     4.0  A woman called a dental office to ask for her ...   \n",
       "5     5.0  A woman in the US has been filmed berating a c...   \n",
       "6     6.0  I had a similar situation when doing customer ...   \n",
       "7     7.0  I quit my job after 20 years and made over 27 ...   \n",
       "8     8.0  I don't blame you for being upset. I would be ...   \n",
       "9     9.0  I was in retail for a decade. I was in a call ...   \n",
       "10   10.0  I work in a call center and we have a lot of c...   \n",
       "11   11.0  I enjoy calls like this. Wait sir what color a...   \n",
       "12   12.0  I have worked in the contact center industry f...   \n",
       "13   13.0  I'm a cable company customer service rep. I've...   \n",
       "14   14.0  I worked in a call centre, one night a woman c...   \n",
       "15   15.0  I worked at a call center for a major credit c...   \n",
       "16   16.0  I'm sure you're aware of the recent changes to...   \n",
       "17   17.0  I once had an elderly couple calling about the...   \n",
       "18   18.0  I'm pretty sure I know where you work and I'm ...   \n",
       "19   19.0  I get a request for a CEO once a week. The cus...   \n",
       "\n",
       "                                          new_summary  \n",
       "0   I work in a call center. I got a call from a v...  \n",
       "1   I had a mother call me one time to request we ...  \n",
       "2   OP is a salesperson who sold a TV to a custome...  \n",
       "3   I'm sorry but I'm not going to give you a clai...  \n",
       "4   I work in a call center. I deal with a lot of ...  \n",
       "5   A woman in the US has been filmed berating a c...  \n",
       "6   I'm an ex-call center worker. I worked for a m...  \n",
       "7   I worked at a call center. We would drink on t...  \n",
       "8   I'm so sorry you had to go through that. Ive h...  \n",
       "9   I've been in a call centre for 5 years. I cry ...  \n",
       "10  I work in a call center and we have a lot of c...  \n",
       "11  I used to work for a credit card processor. We...  \n",
       "12  I have worked in the contact center industry f...  \n",
       "13  I'm a cable company customer service rep. I've...  \n",
       "14  I worked in a call centre, one night a woman c...  \n",
       "15  I'm a call center worker. I get some really di...  \n",
       "16  I'm sure you're aware of the recent changes to...  \n",
       "17  I once had an elderly couple calling about the...  \n",
       "18  The customer is always right. Even when they'r...  \n",
       "19  I get a request for a CEO once a week. The cus...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohere_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f80f1c9eab4cd7b4ed5470a875856e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bcfe9fe8e345b9916425374ae98479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.84 seconds, 10.87 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Select the columns to compare\n",
    "selftext = cohere_comments_df['concatenated_summary']\n",
    "summary = cohere_comments_df['new_summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "cohere_comments_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display average accuracy score for OpenAI, Pegasus, and Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataframe</th>\n",
       "      <th>Average F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>df</td>\n",
       "      <td>0.875641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pegasus_df</td>\n",
       "      <td>0.925182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cohere_df</td>\n",
       "      <td>0.877726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the average F1 scores\n",
    "df_avg_f1 = comments_df['bert_f1'].mean()\n",
    "pegasus_avg_f1 = pegasus_comments_df['bert_f1'].mean()\n",
    "cohere_avg_f1 = cohere_comments_df['bert_f1'].mean()\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "data = {\n",
    "    'Dataframe': ['df', 'pegasus_df', 'cohere_df'],\n",
    "    'Average F1': [df_avg_f1, pegasus_avg_f1, cohere_avg_f1]\n",
    "}\n",
    "\n",
    "# Create a new dataframe to display the results\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the results in a simple table\n",
    "display(HTML(results_df.to_html(index=False)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print OpenAI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 rows were >= 0.8 F1 and 0 were below 0.8 F1.\n"
     ]
    }
   ],
   "source": [
    "temp_df2 = comments_df[comments_df['bert_f1'] < 0.8] \n",
    "temp_df = comments_df[comments_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = temp_df.shape[0]\n",
    "\n",
    "removed_num = temp_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Pegasus results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 rows were >= 0.8 F1 and 0 were below 0.8 F1.\n"
     ]
    }
   ],
   "source": [
    "temp_df2 = pegasus_comments_df[pegasus_comments_df['bert_f1'] < 0.8] \n",
    "temp_df = pegasus_comments_df[pegasus_comments_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = temp_df.shape[0]\n",
    "\n",
    "removed_num = temp_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Cohere results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 rows were >= 0.8 F1 and 2 were below 0.8 F1.\n"
     ]
    }
   ],
   "source": [
    "temp_df2 = cohere_comments_df[cohere_comments_df['bert_f1'] < 0.8] \n",
    "temp_df = cohere_comments_df[cohere_comments_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = temp_df.shape[0]\n",
    "\n",
    "removed_num = temp_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Double check that we still have comments for every top.  Count should = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "unique_count = comments_df['topic'].nunique()\n",
    "\n",
    "print(unique_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegasus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "unique_count = pegasus_comments_df['topic'].nunique()\n",
    "\n",
    "print(unique_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "unique_count = cohere_comments_df['topic'].nunique()\n",
    "\n",
    "print(unique_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export comments with accuracy to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_csv('tfcc_comments_summaries_of_summaries_with_accuracy.csv', index=False)\n",
    "pegasus_comments_df.to_csv('tfcc_pegasus_comments_summaries_of_summaries_with_accuracy.csv', index=False)\n",
    "cohere_comments_df.to_csv('tfcc_cohere_comments_summaries_of_summaries_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate accuracy report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_df = pd.read_csv('tfcc_submissions_summaries_of_summaries_with_accuracy.csv')\n",
    "pegasus_df = pd.read_csv('tfcc_submissions_summaries_of_summaries_pegasus_with_accuracy.csv')\n",
    "cohere_df = pd.read_csv('tfcc_submissions_summaries_of_summaries_cohere_with_accuracy.csv')\n",
    "\n",
    "openai_comments_df = pd.read_csv('tfcc_comments_summaries_of_summaries_with_accuracy.csv')\n",
    "pegasus_comments_df = pd.read_csv('tfcc_pegasus_comments_summaries_of_summaries_with_accuracy.csv')\n",
    "cohere_comments_df = pd.read_csv('tfcc_cohere_comments_summaries_of_summaries_with_accuracy.csv')\n",
    "\n",
    "\n",
    "topics = pd.read_csv('tfcc_top20_topics_with_sentiment_and_comments_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.rename(columns={'Topic': 'topic'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by 'topic' and calculate the mean F1 score for each model\n",
    "openai_average_f1 = openai_df.groupby('topic')['bert_f1'].mean().reset_index().rename(columns={'bert_f1': 'openai_bert_f1'})\n",
    "pegasus_average_f1 = pegasus_df.groupby('topic')['bert_f1'].mean().reset_index().rename(columns={'bert_f1': 'pegasus_bert_f1'})\n",
    "cohere_average_f1 = cohere_df.groupby('topic')['bert_f1'].mean().reset_index().rename(columns={'bert_f1': 'cohere_bert_f1'})\n",
    "\n",
    "# Merge the topics dataframe with the average F1 scores dataframes on the 'topic' column\n",
    "topics_with_f1 = topics.merge(openai_average_f1, on='topic', how='left')\n",
    "topics_with_f1 = topics_with_f1.merge(pegasus_average_f1, on='topic', how='left')\n",
    "topics_with_f1 = topics_with_f1.merge(cohere_average_f1, on='topic', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>avg_pos_sentiment</th>\n",
       "      <th>avg_neg_sentiment</th>\n",
       "      <th>avg_comments_pos_sentiment</th>\n",
       "      <th>avg_comments_neg_sentiment</th>\n",
       "      <th>openai_bert_f1</th>\n",
       "      <th>pegasus_bert_f1</th>\n",
       "      <th>cohere_bert_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>796</td>\n",
       "      <td>0_like_help_name_say</td>\n",
       "      <td>0.161216</td>\n",
       "      <td>0.838784</td>\n",
       "      <td>0.196144</td>\n",
       "      <td>0.803856</td>\n",
       "      <td>0.850991</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.850991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>591</td>\n",
       "      <td>1_card_bank_credit_fraud</td>\n",
       "      <td>0.113983</td>\n",
       "      <td>0.886017</td>\n",
       "      <td>0.148113</td>\n",
       "      <td>0.851887</td>\n",
       "      <td>0.841732</td>\n",
       "      <td>0.900285</td>\n",
       "      <td>0.841732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>2_delivery_shipping_store_email</td>\n",
       "      <td>0.122277</td>\n",
       "      <td>0.877723</td>\n",
       "      <td>0.163302</td>\n",
       "      <td>0.836698</td>\n",
       "      <td>0.843909</td>\n",
       "      <td>0.895476</td>\n",
       "      <td>0.843909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>283</td>\n",
       "      <td>3_insurance_car_claims_coverage</td>\n",
       "      <td>0.103466</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.117970</td>\n",
       "      <td>0.882030</td>\n",
       "      <td>0.847239</td>\n",
       "      <td>0.895246</td>\n",
       "      <td>0.847239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>243</td>\n",
       "      <td>4_patient_doctor_clinic_medical</td>\n",
       "      <td>0.139520</td>\n",
       "      <td>0.860480</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.845988</td>\n",
       "      <td>0.894306</td>\n",
       "      <td>0.845988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>201</td>\n",
       "      <td>5_tow_roadside_truck_assistance</td>\n",
       "      <td>0.159511</td>\n",
       "      <td>0.840489</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>0.860676</td>\n",
       "      <td>0.847994</td>\n",
       "      <td>0.898121</td>\n",
       "      <td>0.847994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>6_bill_phones_service_data</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.103897</td>\n",
       "      <td>0.896103</td>\n",
       "      <td>0.852856</td>\n",
       "      <td>0.895266</td>\n",
       "      <td>0.852856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>108</td>\n",
       "      <td>7_job_feel_anxiety_work</td>\n",
       "      <td>0.154886</td>\n",
       "      <td>0.845114</td>\n",
       "      <td>0.290429</td>\n",
       "      <td>0.709571</td>\n",
       "      <td>0.845393</td>\n",
       "      <td>0.891779</td>\n",
       "      <td>0.845393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>8_english_spanish_speak_language</td>\n",
       "      <td>0.154176</td>\n",
       "      <td>0.845824</td>\n",
       "      <td>0.208100</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.847847</td>\n",
       "      <td>0.893386</td>\n",
       "      <td>0.847847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "      <td>9_job_interview_role_experience</td>\n",
       "      <td>0.374143</td>\n",
       "      <td>0.625857</td>\n",
       "      <td>0.343623</td>\n",
       "      <td>0.656377</td>\n",
       "      <td>0.842245</td>\n",
       "      <td>0.889179</td>\n",
       "      <td>0.842245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>10_hotel_booking_rooms_reservations</td>\n",
       "      <td>0.168714</td>\n",
       "      <td>0.831286</td>\n",
       "      <td>0.101573</td>\n",
       "      <td>0.898427</td>\n",
       "      <td>0.841054</td>\n",
       "      <td>0.897491</td>\n",
       "      <td>0.841054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>96</td>\n",
       "      <td>11_internet_modem_isp_wifi</td>\n",
       "      <td>0.092461</td>\n",
       "      <td>0.907539</td>\n",
       "      <td>0.140897</td>\n",
       "      <td>0.859103</td>\n",
       "      <td>0.842264</td>\n",
       "      <td>0.897525</td>\n",
       "      <td>0.842264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>12_password_reset_login_email</td>\n",
       "      <td>0.091508</td>\n",
       "      <td>0.908492</td>\n",
       "      <td>0.139446</td>\n",
       "      <td>0.860554</td>\n",
       "      <td>0.857499</td>\n",
       "      <td>0.890499</td>\n",
       "      <td>0.857499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>13_cable_channels_service_internet</td>\n",
       "      <td>0.070832</td>\n",
       "      <td>0.929168</td>\n",
       "      <td>0.145947</td>\n",
       "      <td>0.854053</td>\n",
       "      <td>0.844222</td>\n",
       "      <td>0.895039</td>\n",
       "      <td>0.844222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>14_collections_debt_payments_due</td>\n",
       "      <td>0.156431</td>\n",
       "      <td>0.843569</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.841580</td>\n",
       "      <td>0.843852</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>0.843852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>77</td>\n",
       "      <td>15_lurker_poster_long_work</td>\n",
       "      <td>0.159258</td>\n",
       "      <td>0.840742</td>\n",
       "      <td>0.154618</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.853629</td>\n",
       "      <td>0.895540</td>\n",
       "      <td>0.853629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>72</td>\n",
       "      <td>16_chats_email_customers_message</td>\n",
       "      <td>0.142162</td>\n",
       "      <td>0.857838</td>\n",
       "      <td>0.137554</td>\n",
       "      <td>0.862446</td>\n",
       "      <td>0.865514</td>\n",
       "      <td>0.894599</td>\n",
       "      <td>0.865514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>17_flight_airline_airport_flights</td>\n",
       "      <td>0.156098</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.231165</td>\n",
       "      <td>0.768835</td>\n",
       "      <td>0.844177</td>\n",
       "      <td>0.895253</td>\n",
       "      <td>0.844177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>18_meter_heater_complaint_manager</td>\n",
       "      <td>0.079662</td>\n",
       "      <td>0.920338</td>\n",
       "      <td>0.181753</td>\n",
       "      <td>0.818247</td>\n",
       "      <td>0.844085</td>\n",
       "      <td>0.901675</td>\n",
       "      <td>0.844085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>19_supervisor_manager_escalated_get</td>\n",
       "      <td>0.089145</td>\n",
       "      <td>0.910855</td>\n",
       "      <td>0.184708</td>\n",
       "      <td>0.815292</td>\n",
       "      <td>0.859562</td>\n",
       "      <td>0.894837</td>\n",
       "      <td>0.859562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  Count                                 Name  avg_pos_sentiment  \\\n",
       "0       0    796                 0_like_help_name_say           0.161216   \n",
       "1       1    591             1_card_bank_credit_fraud           0.113983   \n",
       "2       2    457      2_delivery_shipping_store_email           0.122277   \n",
       "3       3    283      3_insurance_car_claims_coverage           0.103466   \n",
       "4       4    243      4_patient_doctor_clinic_medical           0.139520   \n",
       "5       5    201      5_tow_roadside_truck_assistance           0.159511   \n",
       "6       6    188           6_bill_phones_service_data           0.133500   \n",
       "7       7    108              7_job_feel_anxiety_work           0.154886   \n",
       "8       8    106     8_english_spanish_speak_language           0.154176   \n",
       "9       9    101      9_job_interview_role_experience           0.374143   \n",
       "10     10     99  10_hotel_booking_rooms_reservations           0.168714   \n",
       "11     11     96           11_internet_modem_isp_wifi           0.092461   \n",
       "12     12     85        12_password_reset_login_email           0.091508   \n",
       "13     13     83   13_cable_channels_service_internet           0.070832   \n",
       "14     14     79     14_collections_debt_payments_due           0.156431   \n",
       "15     15     77           15_lurker_poster_long_work           0.159258   \n",
       "16     16     72     16_chats_email_customers_message           0.142162   \n",
       "17     17     69    17_flight_airline_airport_flights           0.156098   \n",
       "18     18     59    18_meter_heater_complaint_manager           0.079662   \n",
       "19     19     55  19_supervisor_manager_escalated_get           0.089145   \n",
       "\n",
       "    avg_neg_sentiment  avg_comments_pos_sentiment  avg_comments_neg_sentiment  \\\n",
       "0            0.838784                    0.196144                    0.803856   \n",
       "1            0.886017                    0.148113                    0.851887   \n",
       "2            0.877723                    0.163302                    0.836698   \n",
       "3            0.896534                    0.117970                    0.882030   \n",
       "4            0.860480                    0.159091                    0.840909   \n",
       "5            0.840489                    0.139324                    0.860676   \n",
       "6            0.866500                    0.103897                    0.896103   \n",
       "7            0.845114                    0.290429                    0.709571   \n",
       "8            0.845824                    0.208100                    0.791900   \n",
       "9            0.625857                    0.343623                    0.656377   \n",
       "10           0.831286                    0.101573                    0.898427   \n",
       "11           0.907539                    0.140897                    0.859103   \n",
       "12           0.908492                    0.139446                    0.860554   \n",
       "13           0.929168                    0.145947                    0.854053   \n",
       "14           0.843569                    0.158420                    0.841580   \n",
       "15           0.840742                    0.154618                    0.845382   \n",
       "16           0.857838                    0.137554                    0.862446   \n",
       "17           0.843902                    0.231165                    0.768835   \n",
       "18           0.920338                    0.181753                    0.818247   \n",
       "19           0.910855                    0.184708                    0.815292   \n",
       "\n",
       "    openai_bert_f1  pegasus_bert_f1  cohere_bert_f1  \n",
       "0         0.850991         0.891258        0.850991  \n",
       "1         0.841732         0.900285        0.841732  \n",
       "2         0.843909         0.895476        0.843909  \n",
       "3         0.847239         0.895246        0.847239  \n",
       "4         0.845988         0.894306        0.845988  \n",
       "5         0.847994         0.898121        0.847994  \n",
       "6         0.852856         0.895266        0.852856  \n",
       "7         0.845393         0.891779        0.845393  \n",
       "8         0.847847         0.893386        0.847847  \n",
       "9         0.842245         0.889179        0.842245  \n",
       "10        0.841054         0.897491        0.841054  \n",
       "11        0.842264         0.897525        0.842264  \n",
       "12        0.857499         0.890499        0.857499  \n",
       "13        0.844222         0.895039        0.844222  \n",
       "14        0.843852         0.901720        0.843852  \n",
       "15        0.853629         0.895540        0.853629  \n",
       "16        0.865514         0.894599        0.865514  \n",
       "17        0.844177         0.895253        0.844177  \n",
       "18        0.844085         0.901675        0.844085  \n",
       "19        0.859562         0.894837        0.859562  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_with_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_with_f1 = topics_with_f1.drop(columns=['Count', 'avg_pos_sentiment', 'avg_neg_sentiment', 'avg_comments_pos_sentiment', 'avg_comments_neg_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>openai_bert_f1</th>\n",
       "      <th>pegasus_bert_f1</th>\n",
       "      <th>cohere_bert_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_like_help_name_say</td>\n",
       "      <td>0.850991</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.850991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_card_bank_credit_fraud</td>\n",
       "      <td>0.841732</td>\n",
       "      <td>0.900285</td>\n",
       "      <td>0.841732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_delivery_shipping_store_email</td>\n",
       "      <td>0.843909</td>\n",
       "      <td>0.895476</td>\n",
       "      <td>0.843909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3_insurance_car_claims_coverage</td>\n",
       "      <td>0.847239</td>\n",
       "      <td>0.895246</td>\n",
       "      <td>0.847239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4_patient_doctor_clinic_medical</td>\n",
       "      <td>0.845988</td>\n",
       "      <td>0.894306</td>\n",
       "      <td>0.845988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5_tow_roadside_truck_assistance</td>\n",
       "      <td>0.847994</td>\n",
       "      <td>0.898121</td>\n",
       "      <td>0.847994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6_bill_phones_service_data</td>\n",
       "      <td>0.852856</td>\n",
       "      <td>0.895266</td>\n",
       "      <td>0.852856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7_job_feel_anxiety_work</td>\n",
       "      <td>0.845393</td>\n",
       "      <td>0.891779</td>\n",
       "      <td>0.845393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8_english_spanish_speak_language</td>\n",
       "      <td>0.847847</td>\n",
       "      <td>0.893386</td>\n",
       "      <td>0.847847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9_job_interview_role_experience</td>\n",
       "      <td>0.842245</td>\n",
       "      <td>0.889179</td>\n",
       "      <td>0.842245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10_hotel_booking_rooms_reservations</td>\n",
       "      <td>0.841054</td>\n",
       "      <td>0.897491</td>\n",
       "      <td>0.841054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11_internet_modem_isp_wifi</td>\n",
       "      <td>0.842264</td>\n",
       "      <td>0.897525</td>\n",
       "      <td>0.842264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12_password_reset_login_email</td>\n",
       "      <td>0.857499</td>\n",
       "      <td>0.890499</td>\n",
       "      <td>0.857499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13_cable_channels_service_internet</td>\n",
       "      <td>0.844222</td>\n",
       "      <td>0.895039</td>\n",
       "      <td>0.844222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14_collections_debt_payments_due</td>\n",
       "      <td>0.843852</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>0.843852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15_lurker_poster_long_work</td>\n",
       "      <td>0.853629</td>\n",
       "      <td>0.895540</td>\n",
       "      <td>0.853629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16_chats_email_customers_message</td>\n",
       "      <td>0.865514</td>\n",
       "      <td>0.894599</td>\n",
       "      <td>0.865514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17_flight_airline_airport_flights</td>\n",
       "      <td>0.844177</td>\n",
       "      <td>0.895253</td>\n",
       "      <td>0.844177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18_meter_heater_complaint_manager</td>\n",
       "      <td>0.844085</td>\n",
       "      <td>0.901675</td>\n",
       "      <td>0.844085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19_supervisor_manager_escalated_get</td>\n",
       "      <td>0.859562</td>\n",
       "      <td>0.894837</td>\n",
       "      <td>0.859562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                 Name  openai_bert_f1  \\\n",
       "0       0                 0_like_help_name_say        0.850991   \n",
       "1       1             1_card_bank_credit_fraud        0.841732   \n",
       "2       2      2_delivery_shipping_store_email        0.843909   \n",
       "3       3      3_insurance_car_claims_coverage        0.847239   \n",
       "4       4      4_patient_doctor_clinic_medical        0.845988   \n",
       "5       5      5_tow_roadside_truck_assistance        0.847994   \n",
       "6       6           6_bill_phones_service_data        0.852856   \n",
       "7       7              7_job_feel_anxiety_work        0.845393   \n",
       "8       8     8_english_spanish_speak_language        0.847847   \n",
       "9       9      9_job_interview_role_experience        0.842245   \n",
       "10     10  10_hotel_booking_rooms_reservations        0.841054   \n",
       "11     11           11_internet_modem_isp_wifi        0.842264   \n",
       "12     12        12_password_reset_login_email        0.857499   \n",
       "13     13   13_cable_channels_service_internet        0.844222   \n",
       "14     14     14_collections_debt_payments_due        0.843852   \n",
       "15     15           15_lurker_poster_long_work        0.853629   \n",
       "16     16     16_chats_email_customers_message        0.865514   \n",
       "17     17    17_flight_airline_airport_flights        0.844177   \n",
       "18     18    18_meter_heater_complaint_manager        0.844085   \n",
       "19     19  19_supervisor_manager_escalated_get        0.859562   \n",
       "\n",
       "    pegasus_bert_f1  cohere_bert_f1  \n",
       "0          0.891258        0.850991  \n",
       "1          0.900285        0.841732  \n",
       "2          0.895476        0.843909  \n",
       "3          0.895246        0.847239  \n",
       "4          0.894306        0.845988  \n",
       "5          0.898121        0.847994  \n",
       "6          0.895266        0.852856  \n",
       "7          0.891779        0.845393  \n",
       "8          0.893386        0.847847  \n",
       "9          0.889179        0.842245  \n",
       "10         0.897491        0.841054  \n",
       "11         0.897525        0.842264  \n",
       "12         0.890499        0.857499  \n",
       "13         0.895039        0.844222  \n",
       "14         0.901720        0.843852  \n",
       "15         0.895540        0.853629  \n",
       "16         0.894599        0.865514  \n",
       "17         0.895253        0.844177  \n",
       "18         0.901675        0.844085  \n",
       "19         0.894837        0.859562  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_with_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'topic' and calculate the mean F1 score for each model\n",
    "openai_average_f1 = openai_comments_df.groupby('topic')['bert_f1'].mean().reset_index().rename(columns={'bert_f1': 'openai_bert_f1'})\n",
    "pegasus_average_f1 = pegasus_comments_df.groupby('topic')['bert_f1'].mean().reset_index().rename(columns={'bert_f1': 'pegasus_bert_f1'})\n",
    "cohere_average_f1 = cohere_comments_df.groupby('topic')['bert_f1'].mean().reset_index().rename(columns={'bert_f1': 'cohere_bert_f1'})\n",
    "\n",
    "# Merge the topics dataframe with the average F1 scores dataframes on the 'topic' column\n",
    "comments_topics_with_f1 = topics.merge(openai_average_f1, on='topic', how='left')\n",
    "comments_topics_with_f1 = comments_topics_with_f1.merge(pegasus_average_f1, on='topic', how='left')\n",
    "comments_topics_with_f1 = comments_topics_with_f1.merge(cohere_average_f1, on='topic', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_topics_with_f1 = comments_topics_with_f1.drop(columns=['Count','avg_pos_sentiment', 'avg_neg_sentiment', 'avg_comments_pos_sentiment', 'avg_comments_neg_sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>openai_bert_f1</th>\n",
       "      <th>pegasus_bert_f1</th>\n",
       "      <th>cohere_bert_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_like_help_name_say</td>\n",
       "      <td>0.893958</td>\n",
       "      <td>0.924967</td>\n",
       "      <td>0.901824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_card_bank_credit_fraud</td>\n",
       "      <td>0.884805</td>\n",
       "      <td>0.939266</td>\n",
       "      <td>0.849363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_delivery_shipping_store_email</td>\n",
       "      <td>0.876737</td>\n",
       "      <td>0.911328</td>\n",
       "      <td>0.810306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3_insurance_car_claims_coverage</td>\n",
       "      <td>0.889987</td>\n",
       "      <td>0.949932</td>\n",
       "      <td>0.790009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4_patient_doctor_clinic_medical</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>0.933419</td>\n",
       "      <td>0.789450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5_tow_roadside_truck_assistance</td>\n",
       "      <td>0.859110</td>\n",
       "      <td>0.914904</td>\n",
       "      <td>0.893871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6_bill_phones_service_data</td>\n",
       "      <td>0.877826</td>\n",
       "      <td>0.911036</td>\n",
       "      <td>0.802446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7_job_feel_anxiety_work</td>\n",
       "      <td>0.890982</td>\n",
       "      <td>0.910531</td>\n",
       "      <td>0.931457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8_english_spanish_speak_language</td>\n",
       "      <td>0.842684</td>\n",
       "      <td>0.920296</td>\n",
       "      <td>0.870770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9_job_interview_role_experience</td>\n",
       "      <td>0.859843</td>\n",
       "      <td>0.903461</td>\n",
       "      <td>0.879219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10_hotel_booking_rooms_reservations</td>\n",
       "      <td>0.879174</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.917461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11_internet_modem_isp_wifi</td>\n",
       "      <td>0.867400</td>\n",
       "      <td>0.911002</td>\n",
       "      <td>0.922288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12_password_reset_login_email</td>\n",
       "      <td>0.857484</td>\n",
       "      <td>0.928962</td>\n",
       "      <td>0.912680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13_cable_channels_service_internet</td>\n",
       "      <td>0.889156</td>\n",
       "      <td>0.928921</td>\n",
       "      <td>0.913797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14_collections_debt_payments_due</td>\n",
       "      <td>0.848059</td>\n",
       "      <td>0.928816</td>\n",
       "      <td>0.909398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15_lurker_poster_long_work</td>\n",
       "      <td>0.883126</td>\n",
       "      <td>0.937424</td>\n",
       "      <td>0.891096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16_chats_email_customers_message</td>\n",
       "      <td>0.868801</td>\n",
       "      <td>0.937297</td>\n",
       "      <td>0.933638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17_flight_airline_airport_flights</td>\n",
       "      <td>0.917104</td>\n",
       "      <td>0.967884</td>\n",
       "      <td>0.920970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18_meter_heater_complaint_manager</td>\n",
       "      <td>0.832531</td>\n",
       "      <td>0.925391</td>\n",
       "      <td>0.807858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19_supervisor_manager_escalated_get</td>\n",
       "      <td>0.886699</td>\n",
       "      <td>0.907979</td>\n",
       "      <td>0.906623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic                                 Name  openai_bert_f1  \\\n",
       "0       0                 0_like_help_name_say        0.893958   \n",
       "1       1             1_card_bank_credit_fraud        0.884805   \n",
       "2       2      2_delivery_shipping_store_email        0.876737   \n",
       "3       3      3_insurance_car_claims_coverage        0.889987   \n",
       "4       4      4_patient_doctor_clinic_medical        0.863482   \n",
       "5       5      5_tow_roadside_truck_assistance        0.859110   \n",
       "6       6           6_bill_phones_service_data        0.877826   \n",
       "7       7              7_job_feel_anxiety_work        0.890982   \n",
       "8       8     8_english_spanish_speak_language        0.842684   \n",
       "9       9      9_job_interview_role_experience        0.859843   \n",
       "10     10  10_hotel_booking_rooms_reservations        0.879174   \n",
       "11     11           11_internet_modem_isp_wifi        0.867400   \n",
       "12     12        12_password_reset_login_email        0.857484   \n",
       "13     13   13_cable_channels_service_internet        0.889156   \n",
       "14     14     14_collections_debt_payments_due        0.848059   \n",
       "15     15           15_lurker_poster_long_work        0.883126   \n",
       "16     16     16_chats_email_customers_message        0.868801   \n",
       "17     17    17_flight_airline_airport_flights        0.917104   \n",
       "18     18    18_meter_heater_complaint_manager        0.832531   \n",
       "19     19  19_supervisor_manager_escalated_get        0.886699   \n",
       "\n",
       "    pegasus_bert_f1  cohere_bert_f1  \n",
       "0          0.924967        0.901824  \n",
       "1          0.939266        0.849363  \n",
       "2          0.911328        0.810306  \n",
       "3          0.949932        0.790009  \n",
       "4          0.933419        0.789450  \n",
       "5          0.914904        0.893871  \n",
       "6          0.911036        0.802446  \n",
       "7          0.910531        0.931457  \n",
       "8          0.920296        0.870770  \n",
       "9          0.903461        0.879219  \n",
       "10         0.910821        0.917461  \n",
       "11         0.911002        0.922288  \n",
       "12         0.928962        0.912680  \n",
       "13         0.928921        0.913797  \n",
       "14         0.928816        0.909398  \n",
       "15         0.937424        0.891096  \n",
       "16         0.937297        0.933638  \n",
       "17         0.967884        0.920970  \n",
       "18         0.925391        0.807858  \n",
       "19         0.907979        0.906623  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_topics_with_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67cfafb2966ad38f021c3760fdc7d3abae7cbc8d411c26a5ddb66b3636203364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
