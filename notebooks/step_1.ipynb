{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1a1669",
   "metadata": {},
   "source": [
    "### Step 1 - Retrieve and Extract Subreddit Data\n",
    "\n",
    "At the time of writing the pushshift API was down and historical posts were not available.  As a backup, historical subreddit posts from academictorrents.com were retrieved.  Academictorrents.com maintains a repository of the pushshift data.  Data was retrieved from 2005-06 through 2022-12.  Details can be found here: https://academictorrents.com/details/c398a571976c78d346c325bd75c47b82edf6124e.\n",
    "\n",
    "Data was retrieved in a compressed format.  The uncompressed format is an NDJSON file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a46298-b2b4-4cf2-9087-d46ec2ec7469",
   "metadata": {},
   "source": [
    "#### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7766e944-3dbe-4151-b0a2-87716b93162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.5-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20->openai) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (18.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting bertopic\n",
      "  Downloading bertopic-0.14.1-py2.py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hdbscan>=0.8.29\n",
      "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.9/dist-packages (from bertopic) (1.1.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from bertopic) (2.2.2)\n",
      "Collecting plotly>=4.7.0\n",
      "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from bertopic) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.9/dist-packages (from bertopic) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from bertopic) (1.23.4)\n",
      "Collecting umap-learn>=0.5.0\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.29->bertopic) (1.9.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.9/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.32)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->bertopic) (2022.7.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly>=4.7.0->bertopic) (23.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.97)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.21.3)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.13.1+cu116)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=0.4.1->bertopic) (1.12.1+cu116)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.12.0)\n",
      "Collecting numba>=0.49\n",
      "  Downloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.4.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (66.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.12.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2019.11.28)\n",
      "Building wheels for collected packages: hdbscan, umap-learn, pynndescent\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp39-cp39-linux_x86_64.whl size=3580339 sha256=2a181507d5b87fb7469e8da23989ade73716d6c1fa37715ca607cf4cd31bd96b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/ff/97/ad3f429626365e542357cb9bd2c986bc9a88de946776c2a805\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82813 sha256=61dc4a7898f72f9500c7a8a8f53d504aa30bbdacd81e4d5a8a5d8c31666ef792\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/99/10/ed2f3bc57ea29f540470eb43570929e30ae911b2d8353b2ee4\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=7325cc93adb8dabde6c4aaa7f4306999379a1a3c23d069eb9f176600c2022654\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/f1/68/06573189964b879adc978fdb7bf9f77279041bee9f9852d429\n",
      "Successfully built hdbscan umap-learn pynndescent\n",
      "Installing collected packages: tenacity, llvmlite, plotly, numba, pynndescent, hdbscan, umap-learn, bertopic\n",
      "Successfully installed bertopic-0.14.1 hdbscan-0.8.29 llvmlite-0.39.1 numba-0.56.4 plotly-5.14.1 pynndescent-0.5.10 tenacity-8.2.2 umap-learn-0.5.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce4086",
   "metadata": {},
   "source": [
    "#### Import required libraries and read NDJSON file into a pandas dataframe.  Limit to required fields only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a759743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import csv \n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f97742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/talesfromcallcenters_submissions.ndjson' \n",
    "\n",
    "# Read the JSON file directly into a dataframe, selecting the desired columns\n",
    "results = pd.read_json(filename, lines=True)[['id', 'title', 'selftext', 'author', 'score', 'num_comments', 'created_utc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf90bd",
   "metadata": {},
   "source": [
    "#### Drop NaN and view the first 10 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5892abc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yc807</td>\n",
       "      <td>Yes, us lowly call center team members want no...</td>\n",
       "      <td>So there I am, sitting at my desk after time-s...</td>\n",
       "      <td>DovahkENT</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>1345149220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yc4bm</td>\n",
       "      <td>No brain, No pain.</td>\n",
       "      <td>I swear that convergys will hire any moron tha...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>1345145883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yamv8</td>\n",
       "      <td>\"how fast does your modems go ?</td>\n",
       "      <td>Starting off the awesome Subreddit\\n\\nI used t...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>1345080297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yalvt</td>\n",
       "      <td>Welcome to r/talesfromcallcenters</td>\n",
       "      <td>As a former phone monkey myself i thought it w...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>1345079410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ydntm</td>\n",
       "      <td>[I can't tell you] information line, this is P...</td>\n",
       "      <td>Yay!  28th subscriber!\\n\\nI used to work for a...</td>\n",
       "      <td>PoglaTheGrate</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1345215773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17111</th>\n",
       "      <td>zz8ztg</td>\n",
       "      <td>When will they learn?</td>\n",
       "      <td>(Work emergency roadside assistance as a dispa...</td>\n",
       "      <td>HogwartsAlumni25</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1672428178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17112</th>\n",
       "      <td>zzdo0y</td>\n",
       "      <td>\"this is the most pleasant phone call i've had...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>trip90458343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1672439681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>zzgolf</td>\n",
       "      <td>call center anxiety??</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1672447446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>zzk31c</td>\n",
       "      <td>Call Avoidance</td>\n",
       "      <td>Long time lurker here, but I recently found ou...</td>\n",
       "      <td>Ceh0208</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>1672457066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>zzqwd8</td>\n",
       "      <td>Come Kill This Cockroach</td>\n",
       "      <td>Super Mega Short Story\\n\\nI work on the reserv...</td>\n",
       "      <td>JuliusNova</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>1672481600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0       yc807  Yes, us lowly call center team members want no...   \n",
       "1       yc4bm                                 No brain, No pain.   \n",
       "2       yamv8                    \"how fast does your modems go ?   \n",
       "3       yalvt                  Welcome to r/talesfromcallcenters   \n",
       "4       ydntm  [I can't tell you] information line, this is P...   \n",
       "...       ...                                                ...   \n",
       "17111  zz8ztg                              When will they learn?   \n",
       "17112  zzdo0y  \"this is the most pleasant phone call i've had...   \n",
       "17113  zzgolf                              call center anxiety??   \n",
       "17114  zzk31c                                     Call Avoidance   \n",
       "17115  zzqwd8                           Come Kill This Cockroach   \n",
       "\n",
       "                                                selftext            author  \\\n",
       "0      So there I am, sitting at my desk after time-s...         DovahkENT   \n",
       "1      I swear that convergys will hire any moron tha...         [deleted]   \n",
       "2      Starting off the awesome Subreddit\\n\\nI used t...         [deleted]   \n",
       "3      As a former phone monkey myself i thought it w...         [deleted]   \n",
       "4      Yay!  28th subscriber!\\n\\nI used to work for a...     PoglaTheGrate   \n",
       "...                                                  ...               ...   \n",
       "17111  (Work emergency roadside assistance as a dispa...  HogwartsAlumni25   \n",
       "17112                                          [removed]      trip90458343   \n",
       "17113                                          [deleted]         [deleted]   \n",
       "17114  Long time lurker here, but I recently found ou...           Ceh0208   \n",
       "17115  Super Mega Short Story\\n\\nI work on the reserv...        JuliusNova   \n",
       "\n",
       "       score  num_comments  created_utc  \n",
       "0         40            10   1345149220  \n",
       "1         28            10   1345145883  \n",
       "2         34             4   1345080297  \n",
       "3         33             3   1345079410  \n",
       "4         29             4   1345215773  \n",
       "...      ...           ...          ...  \n",
       "17111     30            11   1672428178  \n",
       "17112      1             0   1672439681  \n",
       "17113      1             0   1672447446  \n",
       "17114    147            63   1672457066  \n",
       "17115    150            15   1672481600  \n",
       "\n",
       "[17116 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dropna(axis=1, inplace=True)\n",
    "\n",
    "total_submissions = num_rows = len(results.index)\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe894160",
   "metadata": {},
   "source": [
    "#### Note the [deleted] value in author field.  Check to see if this occurs in the selftext field as well.  Selftext is the body of the submission.  Selftext value of [deleted] will not be useful for the anlaysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b5c635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"[deleted]\" appears 1103 times in the selftext column\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count the number of times \"[deleted]\" appears in the specified column\n",
    "num_deleted = (results['selftext'] == '[deleted]').sum()\n",
    "\n",
    "# Print the result\n",
    "print(f'The word \"[deleted]\" appears {num_deleted} times in the selftext column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7658f61",
   "metadata": {},
   "source": [
    "#### Since the word [deleted] appears we remove those rows from the results in the next step.  Author [deleted], if any, are OK though since we still have the selftext to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf9c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[~results['selftext'].isin(['[deleted]', '[removed]'])]\n",
    "\n",
    "total_usable_submissions = num_rows = len(results.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ddd8d",
   "metadata": {},
   "source": [
    "#### Display the results to get the total row count and a view of the first five and last five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e9bcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yc807</td>\n",
       "      <td>Yes, us lowly call center team members want no...</td>\n",
       "      <td>So there I am, sitting at my desk after time-s...</td>\n",
       "      <td>DovahkENT</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>1345149220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yc4bm</td>\n",
       "      <td>No brain, No pain.</td>\n",
       "      <td>I swear that convergys will hire any moron tha...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>1345145883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yamv8</td>\n",
       "      <td>\"how fast does your modems go ?</td>\n",
       "      <td>Starting off the awesome Subreddit\\n\\nI used t...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>1345080297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yalvt</td>\n",
       "      <td>Welcome to r/talesfromcallcenters</td>\n",
       "      <td>As a former phone monkey myself i thought it w...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>1345079410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ydntm</td>\n",
       "      <td>[I can't tell you] information line, this is P...</td>\n",
       "      <td>Yay!  28th subscriber!\\n\\nI used to work for a...</td>\n",
       "      <td>PoglaTheGrate</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1345215773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17109</th>\n",
       "      <td>zyts64</td>\n",
       "      <td>[long] they're my earbuds and i want them now!</td>\n",
       "      <td>i've been a lurker of this subreddit ever sinc...</td>\n",
       "      <td>secret-tacos</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>1672383546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17110</th>\n",
       "      <td>zz7684</td>\n",
       "      <td>kudos to you guys, I don't know how you do it.</td>\n",
       "      <td>I worked in retail for 7 years, recently took ...</td>\n",
       "      <td>Fact0ry0fSadness</td>\n",
       "      <td>211</td>\n",
       "      <td>54</td>\n",
       "      <td>1672423668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17111</th>\n",
       "      <td>zz8ztg</td>\n",
       "      <td>When will they learn?</td>\n",
       "      <td>(Work emergency roadside assistance as a dispa...</td>\n",
       "      <td>HogwartsAlumni25</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1672428178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>zzk31c</td>\n",
       "      <td>Call Avoidance</td>\n",
       "      <td>Long time lurker here, but I recently found ou...</td>\n",
       "      <td>Ceh0208</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>1672457066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>zzqwd8</td>\n",
       "      <td>Come Kill This Cockroach</td>\n",
       "      <td>Super Mega Short Story\\n\\nI work on the reserv...</td>\n",
       "      <td>JuliusNova</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>1672481600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13813 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0       yc807  Yes, us lowly call center team members want no...   \n",
       "1       yc4bm                                 No brain, No pain.   \n",
       "2       yamv8                    \"how fast does your modems go ?   \n",
       "3       yalvt                  Welcome to r/talesfromcallcenters   \n",
       "4       ydntm  [I can't tell you] information line, this is P...   \n",
       "...       ...                                                ...   \n",
       "17109  zyts64     [long] they're my earbuds and i want them now!   \n",
       "17110  zz7684     kudos to you guys, I don't know how you do it.   \n",
       "17111  zz8ztg                              When will they learn?   \n",
       "17114  zzk31c                                     Call Avoidance   \n",
       "17115  zzqwd8                           Come Kill This Cockroach   \n",
       "\n",
       "                                                selftext            author  \\\n",
       "0      So there I am, sitting at my desk after time-s...         DovahkENT   \n",
       "1      I swear that convergys will hire any moron tha...         [deleted]   \n",
       "2      Starting off the awesome Subreddit\\n\\nI used t...         [deleted]   \n",
       "3      As a former phone monkey myself i thought it w...         [deleted]   \n",
       "4      Yay!  28th subscriber!\\n\\nI used to work for a...     PoglaTheGrate   \n",
       "...                                                  ...               ...   \n",
       "17109  i've been a lurker of this subreddit ever sinc...      secret-tacos   \n",
       "17110  I worked in retail for 7 years, recently took ...  Fact0ry0fSadness   \n",
       "17111  (Work emergency roadside assistance as a dispa...  HogwartsAlumni25   \n",
       "17114  Long time lurker here, but I recently found ou...           Ceh0208   \n",
       "17115  Super Mega Short Story\\n\\nI work on the reserv...        JuliusNova   \n",
       "\n",
       "       score  num_comments  created_utc  \n",
       "0         40            10   1345149220  \n",
       "1         28            10   1345145883  \n",
       "2         34             4   1345080297  \n",
       "3         33             3   1345079410  \n",
       "4         29             4   1345215773  \n",
       "...      ...           ...          ...  \n",
       "17109     61             6   1672383546  \n",
       "17110    211            54   1672423668  \n",
       "17111     30            11   1672428178  \n",
       "17114    147            63   1672457066  \n",
       "17115    150            15   1672481600  \n",
       "\n",
       "[13813 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a882d",
   "metadata": {},
   "source": [
    "#### The created_utc field is showing time from epoch in seconds which is not useful.  This needs to be converted to a readable format and placed in a new field called created_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6087403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_372/3831805690.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['created_date'] = pd.to_datetime(results['created_utc'], unit='s')\n",
      "/tmp/ipykernel_372/3831805690.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results.drop('created_utc', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results['created_date'] = pd.to_datetime(results['created_utc'], unit='s')\n",
    "\n",
    "# Drop the epoch seconds column\n",
    "results.drop('created_utc', axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef15dd",
   "metadata": {},
   "source": [
    "#### Check the dataframe again to ensure that the new field has been populated correctly and the old field dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc539b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yc807</td>\n",
       "      <td>Yes, us lowly call center team members want no...</td>\n",
       "      <td>So there I am, sitting at my desk after time-s...</td>\n",
       "      <td>DovahkENT</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-08-16 20:33:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yc4bm</td>\n",
       "      <td>No brain, No pain.</td>\n",
       "      <td>I swear that convergys will hire any moron tha...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-08-16 19:38:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yamv8</td>\n",
       "      <td>\"how fast does your modems go ?</td>\n",
       "      <td>Starting off the awesome Subreddit\\n\\nI used t...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-08-16 01:24:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yalvt</td>\n",
       "      <td>Welcome to r/talesfromcallcenters</td>\n",
       "      <td>As a former phone monkey myself i thought it w...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-08-16 01:10:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ydntm</td>\n",
       "      <td>[I can't tell you] information line, this is P...</td>\n",
       "      <td>Yay!  28th subscriber!\\n\\nI used to work for a...</td>\n",
       "      <td>PoglaTheGrate</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-08-17 15:02:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17109</th>\n",
       "      <td>zyts64</td>\n",
       "      <td>[long] they're my earbuds and i want them now!</td>\n",
       "      <td>i've been a lurker of this subreddit ever sinc...</td>\n",
       "      <td>secret-tacos</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-12-30 06:59:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17110</th>\n",
       "      <td>zz7684</td>\n",
       "      <td>kudos to you guys, I don't know how you do it.</td>\n",
       "      <td>I worked in retail for 7 years, recently took ...</td>\n",
       "      <td>Fact0ry0fSadness</td>\n",
       "      <td>211</td>\n",
       "      <td>54</td>\n",
       "      <td>2022-12-30 18:07:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17111</th>\n",
       "      <td>zz8ztg</td>\n",
       "      <td>When will they learn?</td>\n",
       "      <td>(Work emergency roadside assistance as a dispa...</td>\n",
       "      <td>HogwartsAlumni25</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-12-30 19:22:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>zzk31c</td>\n",
       "      <td>Call Avoidance</td>\n",
       "      <td>Long time lurker here, but I recently found ou...</td>\n",
       "      <td>Ceh0208</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>2022-12-31 03:24:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>zzqwd8</td>\n",
       "      <td>Come Kill This Cockroach</td>\n",
       "      <td>Super Mega Short Story\\n\\nI work on the reserv...</td>\n",
       "      <td>JuliusNova</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>2022-12-31 10:13:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13813 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0       yc807  Yes, us lowly call center team members want no...   \n",
       "1       yc4bm                                 No brain, No pain.   \n",
       "2       yamv8                    \"how fast does your modems go ?   \n",
       "3       yalvt                  Welcome to r/talesfromcallcenters   \n",
       "4       ydntm  [I can't tell you] information line, this is P...   \n",
       "...       ...                                                ...   \n",
       "17109  zyts64     [long] they're my earbuds and i want them now!   \n",
       "17110  zz7684     kudos to you guys, I don't know how you do it.   \n",
       "17111  zz8ztg                              When will they learn?   \n",
       "17114  zzk31c                                     Call Avoidance   \n",
       "17115  zzqwd8                           Come Kill This Cockroach   \n",
       "\n",
       "                                                selftext            author  \\\n",
       "0      So there I am, sitting at my desk after time-s...         DovahkENT   \n",
       "1      I swear that convergys will hire any moron tha...         [deleted]   \n",
       "2      Starting off the awesome Subreddit\\n\\nI used t...         [deleted]   \n",
       "3      As a former phone monkey myself i thought it w...         [deleted]   \n",
       "4      Yay!  28th subscriber!\\n\\nI used to work for a...     PoglaTheGrate   \n",
       "...                                                  ...               ...   \n",
       "17109  i've been a lurker of this subreddit ever sinc...      secret-tacos   \n",
       "17110  I worked in retail for 7 years, recently took ...  Fact0ry0fSadness   \n",
       "17111  (Work emergency roadside assistance as a dispa...  HogwartsAlumni25   \n",
       "17114  Long time lurker here, but I recently found ou...           Ceh0208   \n",
       "17115  Super Mega Short Story\\n\\nI work on the reserv...        JuliusNova   \n",
       "\n",
       "       score  num_comments        created_date  \n",
       "0         40            10 2012-08-16 20:33:40  \n",
       "1         28            10 2012-08-16 19:38:03  \n",
       "2         34             4 2012-08-16 01:24:57  \n",
       "3         33             3 2012-08-16 01:10:10  \n",
       "4         29             4 2012-08-17 15:02:53  \n",
       "...      ...           ...                 ...  \n",
       "17109     61             6 2022-12-30 06:59:06  \n",
       "17110    211            54 2022-12-30 18:07:48  \n",
       "17111     30            11 2022-12-30 19:22:58  \n",
       "17114    147            63 2022-12-31 03:24:26  \n",
       "17115    150            15 2022-12-31 10:13:20  \n",
       "\n",
       "[13813 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ed9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date:  2012-08-16\n",
      "End date:  2022-12-31\n"
     ]
    }
   ],
   "source": [
    "# extract earliest and latest dates\n",
    "start_date = results['created_date'].min().date()\n",
    "end_date = results['created_date'].max().date()\n",
    "\n",
    "# print results\n",
    "print(\"Start date: \", start_date)\n",
    "print(\"End date: \", end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4bccb",
   "metadata": {},
   "source": [
    "#### Remove posts shorter than 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a35573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "results = results[results['selftext'].apply(word_count) >= 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330c4f1",
   "metadata": {},
   "source": [
    "#### Remove posts that are greater than 874 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfcb7f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcfc5844a9d493caccfb0f9f2693262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b909c8a8b304465ad8435ec852301e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/3.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d59dab8a7b43d292a17b03df8bab84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280c653dddeb44ef822326b30a9ba237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/tmp/ipykernel_372/2935146197.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['token_count'] = results['selftext'].apply(count_tokens)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/pegasus-large')\n",
    "\n",
    "# Define the token count threshold\n",
    "max_tokens = 874\n",
    "\n",
    "# Function to count tokens in a text\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text, truncation=False, max_length=1024))\n",
    "\n",
    "# Apply the token count function to the 'selftext' column\n",
    "results['token_count'] = results['selftext'].apply(count_tokens)\n",
    "\n",
    "# Filter the dataframe\n",
    "filtered_submissions = results[results['token_count'] <= max_tokens]\n",
    "\n",
    "# Drop the 'token_count' column as it's not needed anymore\n",
    "filtered_df = filtered_submissions.drop(columns=['token_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9572d6a",
   "metadata": {},
   "source": [
    "#### Get number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e8bd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yc4bm</td>\n",
       "      <td>No brain, No pain.</td>\n",
       "      <td>I swear that convergys will hire any moron tha...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-08-16 19:38:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yamv8</td>\n",
       "      <td>\"how fast does your modems go ?</td>\n",
       "      <td>Starting off the awesome Subreddit\\n\\nI used t...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-08-16 01:24:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ydntm</td>\n",
       "      <td>[I can't tell you] information line, this is P...</td>\n",
       "      <td>Yay!  28th subscriber!\\n\\nI used to work for a...</td>\n",
       "      <td>PoglaTheGrate</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-08-17 15:02:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yicc4</td>\n",
       "      <td>Dishwasher blues</td>\n",
       "      <td>The stories i've heard amazes me but this one ...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>2012-08-20 05:05:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ymjc0</td>\n",
       "      <td>Tech support agent, and yet I can't touch my c...</td>\n",
       "      <td>At my work we are not allowed to adjust the mo...</td>\n",
       "      <td>hanzors</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>2012-08-22 06:27:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17106</th>\n",
       "      <td>zxk7w2</td>\n",
       "      <td>\"Are you a camel jockey?\" Oh dear God</td>\n",
       "      <td>I just had a call that absolutely takes the ca...</td>\n",
       "      <td>CZJayG</td>\n",
       "      <td>277</td>\n",
       "      <td>41</td>\n",
       "      <td>2022-12-28 20:35:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17107</th>\n",
       "      <td>zxn7bt</td>\n",
       "      <td>Call Totals Giving me Anxiety</td>\n",
       "      <td>Does anyone else have to make a certain amount...</td>\n",
       "      <td>BatBitch1016</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-28 22:31:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17110</th>\n",
       "      <td>zz7684</td>\n",
       "      <td>kudos to you guys, I don't know how you do it.</td>\n",
       "      <td>I worked in retail for 7 years, recently took ...</td>\n",
       "      <td>Fact0ry0fSadness</td>\n",
       "      <td>211</td>\n",
       "      <td>54</td>\n",
       "      <td>2022-12-30 18:07:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17111</th>\n",
       "      <td>zz8ztg</td>\n",
       "      <td>When will they learn?</td>\n",
       "      <td>(Work emergency roadside assistance as a dispa...</td>\n",
       "      <td>HogwartsAlumni25</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-12-30 19:22:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>zzk31c</td>\n",
       "      <td>Call Avoidance</td>\n",
       "      <td>Long time lurker here, but I recently found ou...</td>\n",
       "      <td>Ceh0208</td>\n",
       "      <td>147</td>\n",
       "      <td>63</td>\n",
       "      <td>2022-12-31 03:24:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10130 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "1       yc4bm                                 No brain, No pain.   \n",
       "2       yamv8                    \"how fast does your modems go ?   \n",
       "4       ydntm  [I can't tell you] information line, this is P...   \n",
       "5       yicc4                                   Dishwasher blues   \n",
       "6       ymjc0  Tech support agent, and yet I can't touch my c...   \n",
       "...       ...                                                ...   \n",
       "17106  zxk7w2              \"Are you a camel jockey?\" Oh dear God   \n",
       "17107  zxn7bt                      Call Totals Giving me Anxiety   \n",
       "17110  zz7684     kudos to you guys, I don't know how you do it.   \n",
       "17111  zz8ztg                              When will they learn?   \n",
       "17114  zzk31c                                     Call Avoidance   \n",
       "\n",
       "                                                selftext            author  \\\n",
       "1      I swear that convergys will hire any moron tha...         [deleted]   \n",
       "2      Starting off the awesome Subreddit\\n\\nI used t...         [deleted]   \n",
       "4      Yay!  28th subscriber!\\n\\nI used to work for a...     PoglaTheGrate   \n",
       "5      The stories i've heard amazes me but this one ...         [deleted]   \n",
       "6      At my work we are not allowed to adjust the mo...           hanzors   \n",
       "...                                                  ...               ...   \n",
       "17106  I just had a call that absolutely takes the ca...            CZJayG   \n",
       "17107  Does anyone else have to make a certain amount...      BatBitch1016   \n",
       "17110  I worked in retail for 7 years, recently took ...  Fact0ry0fSadness   \n",
       "17111  (Work emergency roadside assistance as a dispa...  HogwartsAlumni25   \n",
       "17114  Long time lurker here, but I recently found ou...           Ceh0208   \n",
       "\n",
       "       score  num_comments        created_date  \n",
       "1         28            10 2012-08-16 19:38:03  \n",
       "2         34             4 2012-08-16 01:24:57  \n",
       "4         29             4 2012-08-17 15:02:53  \n",
       "5         31            15 2012-08-20 05:05:34  \n",
       "6         40            19 2012-08-22 06:27:29  \n",
       "...      ...           ...                 ...  \n",
       "17106    277            41 2022-12-28 20:35:49  \n",
       "17107     45             7 2022-12-28 22:31:50  \n",
       "17110    211            54 2022-12-30 18:07:48  \n",
       "17111     30            11 2022-12-30 19:22:58  \n",
       "17114    147            63 2022-12-31 03:24:26  \n",
       "\n",
       "[10130 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf50e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_inscope_submissions = num_rows = len(filtered_df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2413d",
   "metadata": {},
   "source": [
    "#### Clean up the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29c47680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove emojis\n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)\n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove unicode characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "    # Remove HTML codes\n",
    "    text = text.replace(\"&amp;nbsp;\", \"\")\n",
    "\n",
    "    # Replace 'tl;dr' with 'in summary'\n",
    "    new_text = text.replace(\"tl;dr\", \"in summary\")\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50c1597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the dataframe\n",
    "filtered_df['selftext'] = filtered_df['selftext'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fd72d",
   "metadata": {},
   "source": [
    "#### Save work to this point by exporting the results dataframe to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b583fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('tfcc_submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e0325a",
   "metadata": {},
   "source": [
    "#### Repeat above steps for comments.  In this case we will only retrieve parent_id (to associate the comment with an original submission), body, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5f0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##talesfromcallcenters_comments\n",
    "\n",
    "filename = '../data/talesfromcallcenters_comments.ndjson'\n",
    "\n",
    "# Read the JSON file directly into a dataframe, selecting the desired columns\n",
    "results = pd.read_json(filename, lines=True)[['parent_id', 'body', 'score']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1554e",
   "metadata": {},
   "source": [
    "#### Drop NaN and display the first few and last rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68931adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_yamv8</td>\n",
       "      <td>OUR HIGH SPEED INTERNET PACKAGE IS SO FAST, YO...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_c5txb4w</td>\n",
       "      <td>hahahahahahaha</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_yalvt</td>\n",
       "      <td>I await with great interest to see what people...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_yamv8</td>\n",
       "      <td>Convergys...in Lake Mary FL?  0_0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_c5u5kzb</td>\n",
       "      <td>No, I'm based in Winnipeg, Manitoba Canada and...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293217</th>\n",
       "      <td>t3_zzqwd8</td>\n",
       "      <td>When I worked front desk for a hotel, someone ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293218</th>\n",
       "      <td>t1_j2dej3k</td>\n",
       "      <td>I've done that but not to avoid calls. It was ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293219</th>\n",
       "      <td>t1_j2dstmw</td>\n",
       "      <td>One time I was having such a bad day and not h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293220</th>\n",
       "      <td>t3_zzqwd8</td>\n",
       "      <td>HAHAHAHAHA!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293221</th>\n",
       "      <td>t1_j2fg29b</td>\n",
       "      <td>This isn't the same thing as that. I would con...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parent_id                                               body  score\n",
       "0         t3_yamv8  OUR HIGH SPEED INTERNET PACKAGE IS SO FAST, YO...     18\n",
       "1       t1_c5txb4w                                    hahahahahahaha       3\n",
       "2         t3_yalvt  I await with great interest to see what people...      7\n",
       "3         t3_yamv8                  Convergys...in Lake Mary FL?  0_0      3\n",
       "4       t1_c5u5kzb  No, I'm based in Winnipeg, Manitoba Canada and...      3\n",
       "...            ...                                                ...    ...\n",
       "293217   t3_zzqwd8  When I worked front desk for a hotel, someone ...     26\n",
       "293218  t1_j2dej3k  I've done that but not to avoid calls. It was ...      7\n",
       "293219  t1_j2dstmw  One time I was having such a bad day and not h...      3\n",
       "293220   t3_zzqwd8                                        HAHAHAHAHA!      5\n",
       "293221  t1_j2fg29b  This isn't the same thing as that. I would con...      3\n",
       "\n",
       "[293222 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.dropna(axis=1, inplace=True)\n",
    "\n",
    "total_comments = num_rows = len(results.index)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676cba9",
   "metadata": {},
   "source": [
    "#### Remove all comments with less than 50 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12b92c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "results = results[results['body'].apply(word_count) >= 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29207220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3_yc807</td>\n",
       "      <td>I'm not too familiar with mortgages but i thin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t3_yc807</td>\n",
       "      <td>While I have no problem in the identification ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>t1_c5x5hyx</td>\n",
       "      <td>I never understood why we make people type in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>t3_ymjc0</td>\n",
       "      <td>this makes me like my call center, everything ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t3_yc4bm</td>\n",
       "      <td>My boyfriend &amp;amp; a few of our friends have w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293208</th>\n",
       "      <td>t1_j2en3sz</td>\n",
       "      <td>I feel that. I love when claimants want a rent...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293211</th>\n",
       "      <td>t1_j2egyx9</td>\n",
       "      <td>I grit my teeth and stayed there, met a handfu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293217</th>\n",
       "      <td>t3_zzqwd8</td>\n",
       "      <td>When I worked front desk for a hotel, someone ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293218</th>\n",
       "      <td>t1_j2dej3k</td>\n",
       "      <td>I've done that but not to avoid calls. It was ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293219</th>\n",
       "      <td>t1_j2dstmw</td>\n",
       "      <td>One time I was having such a bad day and not h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88004 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parent_id                                               body  score\n",
       "6         t3_yc807  I'm not too familiar with mortgages but i thin...      8\n",
       "21        t3_yc807  While I have no problem in the identification ...      4\n",
       "23      t1_c5x5hyx  I never understood why we make people type in ...      3\n",
       "26        t3_ymjc0  this makes me like my call center, everything ...      3\n",
       "30        t3_yc4bm  My boyfriend &amp; a few of our friends have w...      4\n",
       "...            ...                                                ...    ...\n",
       "293208  t1_j2en3sz  I feel that. I love when claimants want a rent...      2\n",
       "293211  t1_j2egyx9  I grit my teeth and stayed there, met a handfu...      2\n",
       "293217   t3_zzqwd8  When I worked front desk for a hotel, someone ...     26\n",
       "293218  t1_j2dej3k  I've done that but not to avoid calls. It was ...      7\n",
       "293219  t1_j2dstmw  One time I was having such a bad day and not h...      3\n",
       "\n",
       "[88004 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e121e1",
   "metadata": {},
   "source": [
    "#### Remove comments > 200 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c764fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/tmp/ipykernel_372/2752546569.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['token_count'] = results['body'].apply(count_tokens)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/pegasus-large')\n",
    "\n",
    "# Define the token count threshold\n",
    "max_tokens = 200\n",
    "\n",
    "# Function to count tokens in a text\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text, truncation=False, max_length=1024))\n",
    "\n",
    "# Apply the token count function to the 'selftext' column\n",
    "results['token_count'] = results['body'].apply(count_tokens)\n",
    "\n",
    "# Filter the dataframe\n",
    "filtered_comments = results[results['token_count'] <= max_tokens]\n",
    "\n",
    "# Drop the 'token_count' column as it's not needed anymore\n",
    "filtered_comments_df = filtered_comments.drop(columns=['token_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88177c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3_yc807</td>\n",
       "      <td>I'm not too familiar with mortgages but i thin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t3_yc807</td>\n",
       "      <td>While I have no problem in the identification ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>t1_c5x5hyx</td>\n",
       "      <td>I never understood why we make people type in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>t3_ymjc0</td>\n",
       "      <td>this makes me like my call center, everything ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>t3_yc4bm</td>\n",
       "      <td>My boyfriend &amp;amp; a few of our friends have w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293203</th>\n",
       "      <td>t1_j2cqjfx</td>\n",
       "      <td>Or when they’ve paid their bill late and we ha...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293208</th>\n",
       "      <td>t1_j2en3sz</td>\n",
       "      <td>I feel that. I love when claimants want a rent...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293217</th>\n",
       "      <td>t3_zzqwd8</td>\n",
       "      <td>When I worked front desk for a hotel, someone ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293218</th>\n",
       "      <td>t1_j2dej3k</td>\n",
       "      <td>I've done that but not to avoid calls. It was ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293219</th>\n",
       "      <td>t1_j2dstmw</td>\n",
       "      <td>One time I was having such a bad day and not h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76842 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parent_id                                               body  score\n",
       "6         t3_yc807  I'm not too familiar with mortgages but i thin...      8\n",
       "21        t3_yc807  While I have no problem in the identification ...      4\n",
       "23      t1_c5x5hyx  I never understood why we make people type in ...      3\n",
       "26        t3_ymjc0  this makes me like my call center, everything ...      3\n",
       "30        t3_yc4bm  My boyfriend &amp; a few of our friends have w...      4\n",
       "...            ...                                                ...    ...\n",
       "293203  t1_j2cqjfx  Or when they’ve paid their bill late and we ha...      3\n",
       "293208  t1_j2en3sz  I feel that. I love when claimants want a rent...      2\n",
       "293217   t3_zzqwd8  When I worked front desk for a hotel, someone ...     26\n",
       "293218  t1_j2dej3k  I've done that but not to avoid calls. It was ...      7\n",
       "293219  t1_j2dstmw  One time I was having such a bad day and not h...      3\n",
       "\n",
       "[76842 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_in_scope_comments = num_rows = len(filtered_comments_df.index)\n",
    "\n",
    "\n",
    "filtered_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30d8e3",
   "metadata": {},
   "source": [
    "#### Clean up the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "928fa68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_comments_df['body'] = filtered_comments_df['body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09375a03",
   "metadata": {},
   "source": [
    "#### Export the comments to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5304bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_comments_df.to_csv('tfcc_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae0bcf",
   "metadata": {},
   "source": [
    "#### Clean up.  Remove the NDJSON files from the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc14578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.remove('talesfromcallcenters_comments.ndjson')\n",
    "\n",
    "os.remove('talesfromcallcenters_submissions.ndjson')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c7cc4",
   "metadata": {},
   "source": [
    "### Wrap up: We now have two CSV files of reddit submissions and posts ready for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c9cf3",
   "metadata": {},
   "source": [
    "### This section creates a CSV file for the introduction section of the RMarkdown report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebde37",
   "metadata": {},
   "source": [
    "#### Create the subreddit meta data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba0e1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json \n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f34d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "error_string = \"{\\\"summary\\\": \\\"none\\\"}\"\n",
    "\n",
    "def getOpenAI_Summary(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"\" + prompt + \"\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    initial_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    print(initial_response)\n",
    "\n",
    "    return initial_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1cb1d1",
   "metadata": {},
   "source": [
    "#### Because Cohere and OpenAI training data included Reddit, it will be able to answer general questions about a specific subreddit.  Here we ask OpenAI to describe the subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63ddd7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tales from Call Centers (TFCC) is a subreddit dedicated to the experiences of individuals working in various call centers across the globe. Established in 2011, this online community has amassed a significant following with a current membership of over 400,000 members. TFCC provides an open space for current and former call center employees to share and discuss their encounters with customers, work conditions, and management. \n",
      "\n",
      "The stories shared on TFCC are diverse in nature and vary from humorous to heartbreaking. A common theme among the posts is the strain that call center work can put on employees. Members often highlight the stringent work schedules, excessive monitoring, and lack of autonomy that makes call centers a challenging work environment. The subreddit also reveals the unpredictable nature of the job, with each interaction with a customer bringing a unique set of challenges. The stories shared on TFCC showcase the lengths employees often have to go to provide satisfactory service to customers, including dealing with abusive or unreasonable client requests. The subreddit has created a platform for workers in the industry to share their experiences with one another, and bring attention to the challenges of call center work that may otherwise go unnoticed. \n",
      "\n",
      "Furthermore, the TFCC subreddit is an excellent resource for individuals looking to gain insight into the inner workings of call centers. The sheer volume of stories shared on the page provides an extensive archive of experiences that can offer a glimpse into the everyday challenges of the job. The subreddit also highlights the importance of customer service in various settings, as even the smallest of interactions can have a significant impact on customers. In summary, the Tales from Call Centers subreddit stands as a powerful testimony to the trials and tribulations of call center work, while also providing valuable lessons for customer service professionals seeking to succeed in their workplace.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Describe the Tales from Call Centers (TFCC) subreddit in two lengthy paragraphs.  Include things like history, volume, and themes.  Write in an academic style:'\n",
    "\n",
    "subreddit_description = getOpenAI_Summary(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e635859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76842"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_name = \"Tales from Call Centers (TFCC)\"\n",
    "subreddit_url = \"https://www.reddit.com/r/talesfromcallcenters/\"\n",
    "total_submissions\n",
    "total_usable_submissions\n",
    "total_inscope_submissions\n",
    "total_comments = num_rows\n",
    "total_in_scope_comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74285073",
   "metadata": {},
   "source": [
    "#### Construct a string that described the number of submissions and comments that were in scope and the date range of the subreddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "023a5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = \"A total of \" + format(total_submissions, ',') + \" subreddit submissions and \" + format(total_comments, ',') + \" associated comments were extracted for the period of \" + str(start_date) + \" through \" + str(end_date) + \" from the \" + subreddit_name + \" subreddit (\" + subreddit_url + \"). Of the total submissions and comments, \" + format(total_usable_submissions, ',') + \" submissions and \" + format(total_in_scope_comments, ',') + \" comments were retained after cleanup (short text, null value removal).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "626ca382",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope2 = \" The following sections summarize each of the top 20 topics identified through topic modeling using the BERTopic library.  The sections are formatted as follows: 1) Topic number plus the BERTopic description 2) Themes identified from OpenAI 3) Sentiment analysis results (note that while all sentiment scores are negative, the comments sentiment are generally more positive than the submissions sentiment) 4) Summaries of Submissions (each paragraph represents between 25 - 50 original submissions that have been summarized twice using abstractive summarization) and 5) Summary of comments (a brief summarization of the top 100 comments related to the topic).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c364d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = scope + scope2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "376296b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_intro = \"The following report was generated completely using the OpenAI GPT 3.5 Turbo API through a series of summarization steps.  It is important to note that one of the common risks associated with abstractive summarization is hallucination, which is the introduction of content not completely relevant to the source text.  Abstractive summarization is not perfect and while there are methods to check the accuracy of an abstractive summary, it is not a guarantee of accuracy.  The intent of this report is to consolidate the submissions to a subreddit over an extended period of time and group those submissions into categories identified using NLP analysis techniques.  Should some of the topics be of interest, then a further review of the original subreddit posts is recommended.  Stephen Drew, 2 April 2023.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02047a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A total of 17,116 subreddit submissions and 76,842 associated comments were extracted for the period of 2012-08-16 through 2022-12-31 from the Tales from Call Centers (TFCC) subreddit (https://www.reddit.com/r/talesfromcallcenters/). Of the total submissions and comments, 13,813 submissions and 76,842 comments were retained after cleanup (short text, null value removal). The following sections summarize each of the top 20 topics identified through topic modeling using the BERTopic library.  The sections are formatted as follows: 1) Topic number plus the BERTopic description 2) Themes identified from OpenAI 3) Sentiment analysis results (note that while all sentiment scores are negative, the comments sentiment are generally more positive than the submissions sentiment) 4) Summaries of Submissions (each paragraph represents between 25 - 50 original submissions that have been summarized twice using abstractive summarization) and 5) Summary of comments (a brief summarization of the top 100 comments related to the topic).'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d93913da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with the variables as values\n",
    "data = {'scope': [scope], 'subreddit_description': [subreddit_description], 'subreddit_name': [subreddit_name], 'description_intro': [description_intro]}\n",
    "\n",
    "# create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6757a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scope</th>\n",
       "      <th>subreddit_description</th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>description_intro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A total of 17,116 subreddit submissions and 76...</td>\n",
       "      <td>Tales from Call Centers (TFCC) is a subreddit ...</td>\n",
       "      <td>Tales from Call Centers (TFCC)</td>\n",
       "      <td>The following report was generated completely ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               scope  \\\n",
       "0  A total of 17,116 subreddit submissions and 76...   \n",
       "\n",
       "                               subreddit_description  \\\n",
       "0  Tales from Call Centers (TFCC) is a subreddit ...   \n",
       "\n",
       "                   subreddit_name  \\\n",
       "0  Tales from Call Centers (TFCC)   \n",
       "\n",
       "                                   description_intro  \n",
       "0  The following report was generated completely ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250ca68",
   "metadata": {},
   "source": [
    "#### Export to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2411531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('subreddit_overview.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032b142-dec9-469f-80b0-a9d6870b0ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "67cfafb2966ad38f021c3760fdc7d3abae7cbc8d411c26a5ddb66b3636203364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
