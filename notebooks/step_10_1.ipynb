{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.  Accuracy Measurement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries, load submissions and comments with summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_nan_rows(df, name):\n",
    "    nan_rows = df[df['summary'].isna()]\n",
    "    nan_rows['source'] = name\n",
    "    return nan_rows\n",
    "\n",
    "# Load DataFrames\n",
    "df = pd.read_csv('tfcc_submissions_top20_with_sentiment_including_comment_sentiment_and_summaries.csv')\n",
    "comments_df = pd.read_csv('tfcc_top_comments_summarized.csv')\n",
    "pegasus_df = pd.read_csv('tfcc_submissions_top20_pegasus_summaries.csv')\n",
    "pegasus_comments_df = pd.read_csv('tfcc_top_comments_pegasus_summarized.csv')\n",
    "cohere_df = pd.read_csv('tfcc_submissions_top20_cohere_summaries.csv')\n",
    "cohere_comments_df = pd.read_csv('tfcc_top_comments_cohere_summarized.csv')\n",
    "\n",
    "# Extract rows with NaN values in the 'summary' column\n",
    "nan_rows_df = pd.DataFrame()\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(df, \"tfcc_submissions_top20_with_sentiment_including_comment_sentiment_and_summaries\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(comments_df, \"tfcc_top_comments_summarized\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(pegasus_df, \"tfcc_submissions_top20_pegasus_summaries\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(pegasus_comments_df, \"tfcc_top_comments_pegasus_summarized\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(cohere_df, \"tfcc_submissions_top20_cohere_summaries\"))\n",
    "nan_rows_df = nan_rows_df.append(extract_nan_rows(cohere_comments_df, \"tfcc_top_comments_cohere_summarized\"))\n",
    "\n",
    "# Remove rows with NaN values from the original DataFrames\n",
    "df = df.dropna(subset=['summary'])\n",
    "comments_df = comments_df.dropna(subset=['summary'])\n",
    "pegasus_df = pegasus_df.dropna(subset=['summary'])\n",
    "pegasus_comments_df = pegasus_comments_df.dropna(subset=['summary'])\n",
    "cohere_df = cohere_df.dropna(subset=['summary'])\n",
    "cohere_comments_df = cohere_comments_df.dropna(subset=['summary'])\n",
    "\n",
    "# Print the DataFrame containing rows with NaN values in the 'summary' column\n",
    "nan_rows_df.to_csv('summary_errors.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_date</th>\n",
       "      <th>selftext_length</th>\n",
       "      <th>topic</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>comments_pos_sentiment</th>\n",
       "      <th>comments_neg_sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>2rfobe</td>\n",
       "      <td>Almost 15 years in callcenter</td>\n",
       "      <td>..and i was unemployed for 3 years. last augus...</td>\n",
       "      <td>reddandy73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-01-05 20:28:47</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.194657</td>\n",
       "      <td>0.805343</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_submissions_top20_pegasus_summaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e01rb8</td>\n",
       "      <td>One of my agents actually said what everyone t...</td>\n",
       "      <td>this happened a couple of weeks ago and is bot...</td>\n",
       "      <td>wirwarennamenlos</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2019-11-22 14:33:25</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498418</td>\n",
       "      <td>0.501582</td>\n",
       "      <td>0.250270</td>\n",
       "      <td>0.749730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_submissions_top20_cohere_summaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b4w6n6</td>\n",
       "      <td>Hung up on a customer today</td>\n",
       "      <td>ill give a little bit of background before i g...</td>\n",
       "      <td>forever_a10ne</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2019-03-24 13:11:29</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235142</td>\n",
       "      <td>0.764858</td>\n",
       "      <td>0.131666</td>\n",
       "      <td>0.868334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_submissions_top20_cohere_summaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cf0t8g</td>\n",
       "      <td>Perv masturbates loudly and the rep documents it</td>\n",
       "      <td>so, i wasn't sure i wanted to put this one her...</td>\n",
       "      <td>TaraJo</td>\n",
       "      <td>920.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2019-07-19 00:48:39</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199540</td>\n",
       "      <td>0.800460</td>\n",
       "      <td>0.392115</td>\n",
       "      <td>0.607885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_submissions_top20_cohere_summaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bqz64k</td>\n",
       "      <td>I Love Karma...</td>\n",
       "      <td>this happened to me a few years ago but it sti...</td>\n",
       "      <td>David-Arroyo</td>\n",
       "      <td>756.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2019-05-20 18:17:20</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645398</td>\n",
       "      <td>0.354602</td>\n",
       "      <td>0.269660</td>\n",
       "      <td>0.730340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_submissions_top20_cohere_summaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I get calls like that all of the time....and f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_top_comments_cohere_summarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I also worked for a military affiliated credit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_top_comments_cohere_summarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I could see a legitimate scenario where someon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_top_comments_cohere_summarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I once had an elderly couple calling about the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_top_comments_cohere_summarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lets see the Craziest. Im not sure if this is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tfcc_top_comments_cohere_summarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "1187  2rfobe                      Almost 15 years in callcenter   \n",
       "3     e01rb8  One of my agents actually said what everyone t...   \n",
       "12    b4w6n6                        Hung up on a customer today   \n",
       "21    cf0t8g   Perv masturbates loudly and the rep documents it   \n",
       "35    bqz64k                                    I Love Karma...   \n",
       "...      ...                                                ...   \n",
       "191      NaN                                                NaN   \n",
       "193      NaN                                                NaN   \n",
       "223      NaN                                                NaN   \n",
       "270      NaN                                                NaN   \n",
       "276      NaN                                                NaN   \n",
       "\n",
       "                                               selftext            author  \\\n",
       "1187  ..and i was unemployed for 3 years. last augus...        reddandy73   \n",
       "3     this happened a couple of weeks ago and is bot...  wirwarennamenlos   \n",
       "12    ill give a little bit of background before i g...     forever_a10ne   \n",
       "21    so, i wasn't sure i wanted to put this one her...            TaraJo   \n",
       "35    this happened to me a few years ago but it sti...      David-Arroyo   \n",
       "...                                                 ...               ...   \n",
       "191   I get calls like that all of the time....and f...               NaN   \n",
       "193   I also worked for a military affiliated credit...               NaN   \n",
       "223   I could see a legitimate scenario where someon...               NaN   \n",
       "270   I once had an elderly couple calling about the...               NaN   \n",
       "276   Lets see the Craziest. Im not sure if this is ...               NaN   \n",
       "\n",
       "       score  num_comments         created_date  selftext_length  topic  \\\n",
       "1187     1.0           4.0  2015-01-05 20:28:47            120.0    9.0   \n",
       "3     1553.0         121.0  2019-11-22 14:33:25            138.0    0.0   \n",
       "12    1128.0          86.0  2019-03-24 13:11:29            395.0    0.0   \n",
       "21     920.0          74.0  2019-07-19 00:48:39            446.0    0.0   \n",
       "35     756.0          58.0  2019-05-20 18:17:20            221.0    0.0   \n",
       "...      ...           ...                  ...              ...    ...   \n",
       "191      NaN           NaN                  NaN              NaN    8.0   \n",
       "193      NaN           NaN                  NaN              NaN    8.0   \n",
       "223      NaN           NaN                  NaN              NaN   11.0   \n",
       "270      NaN           NaN                  NaN              NaN   17.0   \n",
       "276      NaN           NaN                  NaN              NaN   19.0   \n",
       "\n",
       "      pos_sentiment  neg_sentiment  comments_pos_sentiment  \\\n",
       "1187       0.194657       0.805343                0.999371   \n",
       "3          0.498418       0.501582                0.250270   \n",
       "12         0.235142       0.764858                0.131666   \n",
       "21         0.199540       0.800460                0.392115   \n",
       "35         0.645398       0.354602                0.269660   \n",
       "...             ...            ...                     ...   \n",
       "191             NaN            NaN                     NaN   \n",
       "193             NaN            NaN                     NaN   \n",
       "223             NaN            NaN                     NaN   \n",
       "270             NaN            NaN                     NaN   \n",
       "276             NaN            NaN                     NaN   \n",
       "\n",
       "      comments_neg_sentiment summary                                    source  \n",
       "1187                0.000629     NaN  tfcc_submissions_top20_pegasus_summaries  \n",
       "3                   0.749730     NaN   tfcc_submissions_top20_cohere_summaries  \n",
       "12                  0.868334     NaN   tfcc_submissions_top20_cohere_summaries  \n",
       "21                  0.607885     NaN   tfcc_submissions_top20_cohere_summaries  \n",
       "35                  0.730340     NaN   tfcc_submissions_top20_cohere_summaries  \n",
       "...                      ...     ...                                       ...  \n",
       "191                      NaN     NaN       tfcc_top_comments_cohere_summarized  \n",
       "193                      NaN     NaN       tfcc_top_comments_cohere_summarized  \n",
       "223                      NaN     NaN       tfcc_top_comments_cohere_summarized  \n",
       "270                      NaN     NaN       tfcc_top_comments_cohere_summarized  \n",
       "276                      NaN     NaN       tfcc_top_comments_cohere_summarized  \n",
       "\n",
       "[92 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows using the shape attribute\n",
    "start_num_rows = df.shape[0]\n",
    "pegasus_start_num_rows = pegasus_df.shape[0]\n",
    "cohere_start_num_rows = cohere_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI - Measuring accuracy on 1964 rows.\n",
      "Pegasus - Measuring accuracy on 1963 rows.\n",
      "COhere - Measuring accuracy on 1883 rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"OpenAI - Measuring accuracy on \" +str(start_num_rows) + \" rows.\")\n",
    "print(\"Pegasus - Measuring accuracy on \" +str(pegasus_start_num_rows) + \" rows.\")\n",
    "print(\"COhere - Measuring accuracy on \" +str(cohere_start_num_rows) + \" rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Rouge object\n",
    "rouge = Rouge()\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge1_score(row):\n",
    "    try:\n",
    "        scores = rouge.get_scores(row['summary'], row['selftext'])\n",
    "        return scores[0]['rouge-1']  # Return only the ROUGE-1 score\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating ROUGE-1 score: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_f1_score(row):\n",
    "    return row['rouge1_scores']['f']\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rouge for OpenAI submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1-score: 0.29108867246853465\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataframe\n",
    "df['rouge1_scores'] = df.apply(calculate_rouge1_score, axis=1)\n",
    "\n",
    "# Extract F1-score and store it in a new column called 'rouge1_f1_score'\n",
    "df['rouge1_f1_score'] = df.apply(extract_f1_score, axis=1)\n",
    "\n",
    "# Calculate the average ROUGE-1 F1-score\n",
    "average_rouge1_f1 = df['rouge1_f1_score'].mean()\n",
    "\n",
    "# Print the average ROUGE-1 F1-score\n",
    "print(f\"Average ROUGE-1 F1-score: {average_rouge1_f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rouge for Pegasus submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1-score: 0.3557169809484121\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataframe\n",
    "pegasus_df['rouge1_scores'] = pegasus_df.apply(calculate_rouge1_score, axis=1)\n",
    "\n",
    "# Extract F1-score and store it in a new column called 'rouge1_f1_score'\n",
    "pegasus_df['rouge1_f1_score'] = pegasus_df.apply(extract_f1_score, axis=1)\n",
    "\n",
    "# Calculate the average ROUGE-1 F1-score\n",
    "average_rouge1_f1 = pegasus_df['rouge1_f1_score'].mean()\n",
    "\n",
    "# Print the average ROUGE-1 F1-score\n",
    "print(f\"Average ROUGE-1 F1-score: {average_rouge1_f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rouge for Cohere submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1-score: 0.41162155878564466\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataframe\n",
    "cohere_df['rouge1_scores'] = cohere_df.apply(calculate_rouge1_score, axis=1)\n",
    "\n",
    "# Extract F1-score and store it in a new column called 'rouge1_f1_score'\n",
    "cohere_df['rouge1_f1_score'] = cohere_df.apply(extract_f1_score, axis=1)\n",
    "\n",
    "# Calculate the average ROUGE-1 F1-score\n",
    "average_rouge1_f1 = cohere_df['rouge1_f1_score'].mean()\n",
    "\n",
    "# Print the average ROUGE-1 F1-score\n",
    "print(f\"Average ROUGE-1 F1-score: {average_rouge1_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_date</th>\n",
       "      <th>selftext_length</th>\n",
       "      <th>topic</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>comments_pos_sentiment</th>\n",
       "      <th>comments_neg_sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9odgd4</td>\n",
       "      <td>If you cuss before you tell me why, I'm hangin...</td>\n",
       "      <td>so. this just happened. i had a caller, we wil...</td>\n",
       "      <td>sleepernick</td>\n",
       "      <td>4183</td>\n",
       "      <td>167</td>\n",
       "      <td>2018-10-15 15:03:20</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>0.167575</td>\n",
       "      <td>0.832425</td>\n",
       "      <td>A rude caller was disconnected by Sleeper Nick...</td>\n",
       "      <td>{'rouge-1': {'r': 0.10714285714285714, 'p': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acncqg</td>\n",
       "      <td>I swear I’m not usually this dumb: when the ca...</td>\n",
       "      <td>my absolute favorite type of calls are when th...</td>\n",
       "      <td>QuoteTheKitty</td>\n",
       "      <td>2002</td>\n",
       "      <td>63</td>\n",
       "      <td>2019-01-04 22:13:45</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360828</td>\n",
       "      <td>0.639172</td>\n",
       "      <td>0.239294</td>\n",
       "      <td>0.760706</td>\n",
       "      <td>A customer telling a customer service represen...</td>\n",
       "      <td>{'rouge-1': {'r': 0.1588785046728972, 'p': 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>js29up</td>\n",
       "      <td>The mute button is not the customers friend</td>\n",
       "      <td>at a previous call center i worked they wanted...</td>\n",
       "      <td>supersizedlady</td>\n",
       "      <td>1756</td>\n",
       "      <td>115</td>\n",
       "      <td>2020-11-11 05:30:44</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.996277</td>\n",
       "      <td>0.305934</td>\n",
       "      <td>0.694066</td>\n",
       "      <td>The writer worked in a call center and preferr...</td>\n",
       "      <td>{'rouge-1': {'r': 0.18181818181818182, 'p': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e01rb8</td>\n",
       "      <td>One of my agents actually said what everyone t...</td>\n",
       "      <td>this happened a couple of weeks ago and is bot...</td>\n",
       "      <td>wirwarennamenlos</td>\n",
       "      <td>1553</td>\n",
       "      <td>121</td>\n",
       "      <td>2019-11-22 14:33:25</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498418</td>\n",
       "      <td>0.501582</td>\n",
       "      <td>0.250270</td>\n",
       "      <td>0.749730</td>\n",
       "      <td>An agent was recorded responding with \"how the...</td>\n",
       "      <td>{'rouge-1': {'r': 0.23469387755102042, 'p': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h0gvxc</td>\n",
       "      <td>Customer loves his analogy until I use it agai...</td>\n",
       "      <td>this call was from a while ago so i don't real...</td>\n",
       "      <td>BostonB96</td>\n",
       "      <td>1411</td>\n",
       "      <td>42</td>\n",
       "      <td>2020-06-10 18:28:42</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184346</td>\n",
       "      <td>0.815654</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.998282</td>\n",
       "      <td>A software provider received a call from a cus...</td>\n",
       "      <td>{'rouge-1': {'r': 0.19148936170212766, 'p': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>4oloj6</td>\n",
       "      <td>Shooter threat</td>\n",
       "      <td>wednesday night, someone called in and threate...</td>\n",
       "      <td>Believeinthis</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-06-17 22:08:20</td>\n",
       "      <td>149</td>\n",
       "      <td>19</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.998582</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.998781</td>\n",
       "      <td>An unknown person called in and threatened to ...</td>\n",
       "      <td>{'rouge-1': {'r': 0.422680412371134, 'p': 0.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>2dbpxp</td>\n",
       "      <td>How come people assume call center employees a...</td>\n",
       "      <td>i've had a few infuriating calls. people just ...</td>\n",
       "      <td>lacquerqueen</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>2014-08-12 11:05:09</td>\n",
       "      <td>254</td>\n",
       "      <td>19</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.998988</td>\n",
       "      <td>0.150063</td>\n",
       "      <td>0.849937</td>\n",
       "      <td>The author is frustrated with the assumption t...</td>\n",
       "      <td>{'rouge-1': {'r': 0.1488095238095238, 'p': 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>4x4pjt</td>\n",
       "      <td>Probably getting a CA because I didn't apologi...</td>\n",
       "      <td>customer complained that i blew her off  despi...</td>\n",
       "      <td>evosthunder</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-08-10 22:06:34</td>\n",
       "      <td>104</td>\n",
       "      <td>19</td>\n",
       "      <td>0.013253</td>\n",
       "      <td>0.986747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A customer complained about being blown off de...</td>\n",
       "      <td>{'rouge-1': {'r': 0.4074074074074074, 'p': 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>2ldeab</td>\n",
       "      <td>Don't Feed Stray Cats</td>\n",
       "      <td>about two years ago, an old lady got upset and...</td>\n",
       "      <td>EveryoneHatesCJ</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-05 15:11:42</td>\n",
       "      <td>125</td>\n",
       "      <td>19</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.994625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An old lady, upset about an issue, requested t...</td>\n",
       "      <td>{'rouge-1': {'r': 0.47560975609756095, 'p': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>2n4jb3</td>\n",
       "      <td>Short and sweet. I air grabbed.</td>\n",
       "      <td>i work as senior level support. (manager escal...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-23 00:41:51</td>\n",
       "      <td>157</td>\n",
       "      <td>19</td>\n",
       "      <td>0.509272</td>\n",
       "      <td>0.490728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a senior level support manager, the speaker...</td>\n",
       "      <td>{'rouge-1': {'r': 0.2336448598130841, 'p': 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1964 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0     9odgd4  If you cuss before you tell me why, I'm hangin...   \n",
       "1     acncqg  I swear I’m not usually this dumb: when the ca...   \n",
       "2     js29up        The mute button is not the customers friend   \n",
       "3     e01rb8  One of my agents actually said what everyone t...   \n",
       "4     h0gvxc  Customer loves his analogy until I use it agai...   \n",
       "...      ...                                                ...   \n",
       "1959  4oloj6                                     Shooter threat   \n",
       "1960  2dbpxp  How come people assume call center employees a...   \n",
       "1961  4x4pjt  Probably getting a CA because I didn't apologi...   \n",
       "1962  2ldeab                              Don't Feed Stray Cats   \n",
       "1963  2n4jb3                    Short and sweet. I air grabbed.   \n",
       "\n",
       "                                               selftext            author  \\\n",
       "0     so. this just happened. i had a caller, we wil...       sleepernick   \n",
       "1     my absolute favorite type of calls are when th...     QuoteTheKitty   \n",
       "2     at a previous call center i worked they wanted...    supersizedlady   \n",
       "3     this happened a couple of weeks ago and is bot...  wirwarennamenlos   \n",
       "4     this call was from a while ago so i don't real...         BostonB96   \n",
       "...                                                 ...               ...   \n",
       "1959  wednesday night, someone called in and threate...     Believeinthis   \n",
       "1960  i've had a few infuriating calls. people just ...      lacquerqueen   \n",
       "1961  customer complained that i blew her off  despi...       evosthunder   \n",
       "1962  about two years ago, an old lady got upset and...   EveryoneHatesCJ   \n",
       "1963  i work as senior level support. (manager escal...         [deleted]   \n",
       "\n",
       "      score  num_comments         created_date  selftext_length  topic  \\\n",
       "0      4183           167  2018-10-15 15:03:20              317      0   \n",
       "1      2002            63  2019-01-04 22:13:45              173      0   \n",
       "2      1756           115  2020-11-11 05:30:44              240      0   \n",
       "3      1553           121  2019-11-22 14:33:25              138      0   \n",
       "4      1411            42  2020-06-10 18:28:42              330      0   \n",
       "...     ...           ...                  ...              ...    ...   \n",
       "1959     18            20  2016-06-17 22:08:20              149     19   \n",
       "1960     15            21  2014-08-12 11:05:09              254     19   \n",
       "1961     14             4  2016-08-10 22:06:34              104     19   \n",
       "1962      7             3  2014-11-05 15:11:42              125     19   \n",
       "1963      1             0  2014-11-23 00:41:51              157     19   \n",
       "\n",
       "      pos_sentiment  neg_sentiment  comments_pos_sentiment  \\\n",
       "0          0.002438       0.997562                0.167575   \n",
       "1          0.360828       0.639172                0.239294   \n",
       "2          0.003723       0.996277                0.305934   \n",
       "3          0.498418       0.501582                0.250270   \n",
       "4          0.184346       0.815654                0.001718   \n",
       "...             ...            ...                     ...   \n",
       "1959       0.001418       0.998582                0.001219   \n",
       "1960       0.001012       0.998988                0.150063   \n",
       "1961       0.013253       0.986747                     NaN   \n",
       "1962       0.005375       0.994625                     NaN   \n",
       "1963       0.509272       0.490728                     NaN   \n",
       "\n",
       "      comments_neg_sentiment  \\\n",
       "0                   0.832425   \n",
       "1                   0.760706   \n",
       "2                   0.694066   \n",
       "3                   0.749730   \n",
       "4                   0.998282   \n",
       "...                      ...   \n",
       "1959                0.998781   \n",
       "1960                0.849937   \n",
       "1961                     NaN   \n",
       "1962                     NaN   \n",
       "1963                     NaN   \n",
       "\n",
       "                                                summary  \\\n",
       "0     A rude caller was disconnected by Sleeper Nick...   \n",
       "1     A customer telling a customer service represen...   \n",
       "2     The writer worked in a call center and preferr...   \n",
       "3     An agent was recorded responding with \"how the...   \n",
       "4     A software provider received a call from a cus...   \n",
       "...                                                 ...   \n",
       "1959  An unknown person called in and threatened to ...   \n",
       "1960  The author is frustrated with the assumption t...   \n",
       "1961  A customer complained about being blown off de...   \n",
       "1962  An old lady, upset about an issue, requested t...   \n",
       "1963  As a senior level support manager, the speaker...   \n",
       "\n",
       "                                           rouge_scores  \n",
       "0     {'rouge-1': {'r': 0.10714285714285714, 'p': 0....  \n",
       "1     {'rouge-1': {'r': 0.1588785046728972, 'p': 0.3...  \n",
       "2     {'rouge-1': {'r': 0.18181818181818182, 'p': 0....  \n",
       "3     {'rouge-1': {'r': 0.23469387755102042, 'p': 0....  \n",
       "4     {'rouge-1': {'r': 0.19148936170212766, 'p': 0....  \n",
       "...                                                 ...  \n",
       "1959  {'rouge-1': {'r': 0.422680412371134, 'p': 0.57...  \n",
       "1960  {'rouge-1': {'r': 0.1488095238095238, 'p': 0.5...  \n",
       "1961  {'rouge-1': {'r': 0.4074074074074074, 'p': 0.4...  \n",
       "1962  {'rouge-1': {'r': 0.47560975609756095, 'p': 0....  \n",
       "1963  {'rouge-1': {'r': 0.2336448598130841, 'p': 0.4...  \n",
       "\n",
       "[1964 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy for Pegasus submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1285c4c5bba24bfda3db9d82d2cba192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97813a528024ec2b76d5d321f62e557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 102.52 seconds, 19.15 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "selftext = pegasus_df['selftext']\n",
    "summary = pegasus_df['summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "pegasus_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate accuracy for Cohere submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f84ba35ae2493ca66b02ef17242b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dfb45dedfd4d11b51c27b32bb80d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 104.49 seconds, 18.02 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "selftext = cohere_df['selftext']\n",
    "summary = cohere_df['summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "cohere_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display average accuracy score for OpenAI, Pegasus, and Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataframe</th>\n",
       "      <th>Average F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>df</td>\n",
       "      <td>0.842497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pegasus_df</td>\n",
       "      <td>0.847639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cohere_df</td>\n",
       "      <td>0.869656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Assuming you have already loaded the dataframes: df, pegasus_df, and cohere_df\n",
    "\n",
    "# Calculate the average F1 scores\n",
    "df_avg_f1 = df['bert_f1'].mean()\n",
    "pegasus_avg_f1 = pegasus_df['bert_f1'].mean()\n",
    "cohere_avg_f1 = cohere_df['bert_f1'].mean()\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "data = {\n",
    "    'Dataframe': ['df', 'pegasus_df', 'cohere_df'],\n",
    "    'Average F1': [df_avg_f1, pegasus_avg_f1, cohere_avg_f1]\n",
    "}\n",
    "\n",
    "# Create a new dataframe to display the results\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the results in a simple table\n",
    "display(HTML(results_df.to_html(index=False)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results for OpenAI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943 rows were >= 0.8 F1 and 21 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "df2 = df[df['bert_f1'] < 0.8] \n",
    "df = df[df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = df.shape[0]\n",
    "\n",
    "removed_num = df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tfcc_submissions_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results for Pegasus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957 rows were >= 0.8 F1 and 6 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "pegasus_df2 = pegasus_df[pegasus_df['bert_f1'] < 0.8] \n",
    "pegasus_df = pegasus_df[pegasus_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = pegasus_df.shape[0]\n",
    "\n",
    "removed_num = pegasus_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasus_df.to_csv('tfcc_submissions_pegasus_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results for Cohere test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849 rows were >= 0.8 F1 and 34 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "cohere_df2 = cohere_df[cohere_df['bert_f1'] < 0.8] \n",
    "cohere_df = cohere_df[cohere_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = cohere_df.shape[0]\n",
    "\n",
    "removed_num = cohere_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_df.to_csv('tfcc_submissions_cohere_with_accuracy.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat accuracy measurement process for comments.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Measuring accuracy on 285 rows.\n",
      "Pegasus Measuring accuracy on 285 rows.\n",
      "Cohere Measuring accuracy on 275 rows.\n"
     ]
    }
   ],
   "source": [
    "# get the number of rows using the shape attribute\n",
    "start_num_rows = comments_df.shape[0]\n",
    "print(\"OpenAI Measuring accuracy on \" +str(start_num_rows) + \" rows.\")\n",
    "\n",
    "pegasus_start_num_rows = pegasus_comments_df.shape[0]\n",
    "print(\"Pegasus Measuring accuracy on \" +str(pegasus_start_num_rows) + \" rows.\")\n",
    "\n",
    "cohere_start_num_rows = cohere_comments_df.shape[0]\n",
    "print(\"Cohere Measuring accuracy on \" +str(cohere_start_num_rows) + \" rows.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure OpenAI comments summaries accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670d792059c8490c8b843c42628fb45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c364630a954f88a96a435cf41266d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 19.07 seconds, 14.95 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Select the columns to compare\n",
    "selftext = comments_df['selftext']\n",
    "summary = comments_df['summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "comments_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure Pegasus comments summaries accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b6f6529f464171a5c596358f83ab02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a7c6d03704456dbd064e1497788626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.50 seconds, 10.00 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Select the columns to compare\n",
    "selftext = pegasus_comments_df['selftext']\n",
    "summary = pegasus_comments_df['summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "pegasus_comments_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure Cohere comments summaries accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f3c11069794594b06014c71743a3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dfaa04e41f40988d830b4a8daa9490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 18.30 seconds, 15.03 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# Select the columns to compare\n",
    "selftext = cohere_comments_df['selftext']\n",
    "summary = cohere_comments_df['summary']\n",
    "\n",
    "# Compute the BERTScore for each pair of text\n",
    "P, R, F1 = bert_score.score(selftext.tolist(), summary.tolist(), lang='en', verbose=True)\n",
    "cohere_comments_df['bert_f1'] = F1.tolist()\n",
    "\n",
    "# Free up GPU memory\n",
    "del P, R, F1\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display average accuracy score for OpenAI, Pegasus, and Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataframe</th>\n",
       "      <th>Average F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>df</td>\n",
       "      <td>0.815775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pegasus_df</td>\n",
       "      <td>0.828468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cohere_df</td>\n",
       "      <td>0.819117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the average F1 scores\n",
    "df_avg_f1 = comments_df['bert_f1'].mean()\n",
    "pegasus_avg_f1 = pegasus_comments_df['bert_f1'].mean()\n",
    "cohere_avg_f1 = cohere_comments_df['bert_f1'].mean()\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "data = {\n",
    "    'Dataframe': ['df', 'pegasus_df', 'cohere_df'],\n",
    "    'Average F1': [df_avg_f1, pegasus_avg_f1, cohere_avg_f1]\n",
    "}\n",
    "\n",
    "# Create a new dataframe to display the results\n",
    "results_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the results in a simple table\n",
    "display(HTML(results_df.to_html(index=False)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print OpenAI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 rows were >= 0.8 F1 and 6 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "comments_df2 = comments_df[comments_df['bert_f1'] < 0.8] \n",
    "comments_df = comments_df[comments_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = comments_df.shape[0]\n",
    "\n",
    "removed_num = comments_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Pegasus results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 rows were >= 0.8 F1 and 0 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "pegasus_comments_df2 = pegasus_comments_df[pegasus_comments_df['bert_f1'] < 0.8] \n",
    "pegasus_comments_df = pegasus_comments_df[pegasus_comments_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = pegasus_comments_df.shape[0]\n",
    "\n",
    "removed_num = pegasus_comments_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Cohere results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 rows were >= 0.8 F1 and 33 were below 0.8 F1 and have been removed.\n"
     ]
    }
   ],
   "source": [
    "cohere_comments_df2 = cohere_comments_df[cohere_comments_df['bert_f1'] < 0.8] \n",
    "cohere_comments_df = cohere_comments_df[cohere_comments_df['bert_f1'] >= 0.8]\n",
    "\n",
    "end_num_rows = cohere_comments_df.shape[0]\n",
    "\n",
    "removed_num = cohere_comments_df2.shape[0]\n",
    "\n",
    "print(str(end_num_rows) + \" rows were >= 0.8 F1 and \" + str(removed_num) + \" were below 0.8 F1 and have been removed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Double check that we still have comments for every top.  Count should = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = comments_df['topic'].nunique()\n",
    "\n",
    "print(unique_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegasus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "unique_count = pegasus_comments_df['topic'].nunique()\n",
    "\n",
    "print(unique_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "unique_count = cohere_comments_df['topic'].nunique()\n",
    "\n",
    "print(unique_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export comments with accuracy to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_csv('tfcc_comments_with_accuracy.csv', index=False)\n",
    "pegasus_comments_df.to_csv('tfcc_pegasus_comments_with_accuracy.csv', index=False)\n",
    "cohere_comments_df.to_csv('tfcc_cohere_comments_with_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67cfafb2966ad38f021c3760fdc7d3abae7cbc8d411c26a5ddb66b3636203364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
